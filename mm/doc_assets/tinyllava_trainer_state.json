{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 1250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01,
      "grad_norm": 2.2820956707000732,
      "learning_rate": 2.631578947368421e-06,
      "loss": 2.6259,
      "step": 1
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.27932071685791,
      "learning_rate": 5.263157894736842e-06,
      "loss": 2.6015,
      "step": 2
    },
    {
      "epoch": 0.02,
      "grad_norm": 2.3406331539154053,
      "learning_rate": 7.894736842105263e-06,
      "loss": 2.4337,
      "step": 3
    },
    {
      "epoch": 0.03,
      "grad_norm": 2.1273703575134277,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 2.732,
      "step": 4
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.6032016277313232,
      "learning_rate": 1.3157894736842106e-05,
      "loss": 2.7429,
      "step": 5
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9321022033691406,
      "learning_rate": 1.5789473684210526e-05,
      "loss": 2.4251,
      "step": 6
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.9910341501235962,
      "learning_rate": 1.8421052631578947e-05,
      "loss": 2.6204,
      "step": 7
    },
    {
      "epoch": 0.06,
      "grad_norm": 2.0626144409179688,
      "learning_rate": 2.105263157894737e-05,
      "loss": 2.6241,
      "step": 8
    },
    {
      "epoch": 0.07,
      "grad_norm": 2.042564630508423,
      "learning_rate": 2.368421052631579e-05,
      "loss": 2.2785,
      "step": 9
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.8735545873641968,
      "learning_rate": 2.6315789473684212e-05,
      "loss": 2.4177,
      "step": 10
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.8706384897232056,
      "learning_rate": 2.8947368421052634e-05,
      "loss": 2.3712,
      "step": 11
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1549947261810303,
      "learning_rate": 3.157894736842105e-05,
      "loss": 2.2084,
      "step": 12
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.1174495220184326,
      "learning_rate": 3.421052631578947e-05,
      "loss": 2.1625,
      "step": 13
    },
    {
      "epoch": 0.11,
      "grad_norm": 2.225268602371216,
      "learning_rate": 3.6842105263157895e-05,
      "loss": 2.4103,
      "step": 14
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.2074477672576904,
      "learning_rate": 3.9473684210526316e-05,
      "loss": 2.2939,
      "step": 15
    },
    {
      "epoch": 0.13,
      "grad_norm": 2.213169813156128,
      "learning_rate": 4.210526315789474e-05,
      "loss": 2.3018,
      "step": 16
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.011589527130127,
      "learning_rate": 4.473684210526316e-05,
      "loss": 1.895,
      "step": 17
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.3954365253448486,
      "learning_rate": 4.736842105263158e-05,
      "loss": 2.165,
      "step": 18
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.087933301925659,
      "learning_rate": 5e-05,
      "loss": 2.157,
      "step": 19
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.395369529724121,
      "learning_rate": 5.2631578947368424e-05,
      "loss": 2.2371,
      "step": 20
    },
    {
      "epoch": 0.17,
      "grad_norm": 2.6875362396240234,
      "learning_rate": 5.526315789473685e-05,
      "loss": 2.4554,
      "step": 21
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0956645011901855,
      "learning_rate": 5.789473684210527e-05,
      "loss": 1.9862,
      "step": 22
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.180840015411377,
      "learning_rate": 6.052631578947369e-05,
      "loss": 2.1635,
      "step": 23
    },
    {
      "epoch": 0.19,
      "grad_norm": 2.3820688724517822,
      "learning_rate": 6.31578947368421e-05,
      "loss": 2.2949,
      "step": 24
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.450519561767578,
      "learning_rate": 6.578947368421054e-05,
      "loss": 2.3469,
      "step": 25
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.1677613258361816,
      "learning_rate": 6.842105263157895e-05,
      "loss": 2.1483,
      "step": 26
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.2783498764038086,
      "learning_rate": 7.105263157894737e-05,
      "loss": 2.2132,
      "step": 27
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.189849376678467,
      "learning_rate": 7.368421052631579e-05,
      "loss": 2.0893,
      "step": 28
    },
    {
      "epoch": 0.23,
      "grad_norm": 2.022064685821533,
      "learning_rate": 7.631578947368422e-05,
      "loss": 2.1602,
      "step": 29
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.9865492582321167,
      "learning_rate": 7.894736842105263e-05,
      "loss": 1.9509,
      "step": 30
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.8693593740463257,
      "learning_rate": 8.157894736842105e-05,
      "loss": 2.0661,
      "step": 31
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.998044729232788,
      "learning_rate": 8.421052631578948e-05,
      "loss": 2.0208,
      "step": 32
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.614470958709717,
      "learning_rate": 8.68421052631579e-05,
      "loss": 2.3331,
      "step": 33
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.263029098510742,
      "learning_rate": 8.947368421052632e-05,
      "loss": 1.9676,
      "step": 34
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.0823400020599365,
      "learning_rate": 9.210526315789474e-05,
      "loss": 1.9308,
      "step": 35
    },
    {
      "epoch": 0.29,
      "grad_norm": 2.5937108993530273,
      "learning_rate": 9.473684210526316e-05,
      "loss": 2.1166,
      "step": 36
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.306910276412964,
      "learning_rate": 9.736842105263158e-05,
      "loss": 1.9583,
      "step": 37
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.3584423065185547,
      "learning_rate": 0.0001,
      "loss": 2.1383,
      "step": 38
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.9784990549087524,
      "learning_rate": 9.999983202901413e-05,
      "loss": 1.6357,
      "step": 39
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.1733627319335938,
      "learning_rate": 9.999932811718506e-05,
      "loss": 2.3201,
      "step": 40
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.08701491355896,
      "learning_rate": 9.999848826789853e-05,
      "loss": 2.008,
      "step": 41
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.232731819152832,
      "learning_rate": 9.999731248679733e-05,
      "loss": 2.5152,
      "step": 42
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.0128633975982666,
      "learning_rate": 9.999580078178135e-05,
      "loss": 2.1834,
      "step": 43
    },
    {
      "epoch": 0.35,
      "grad_norm": 2.005023956298828,
      "learning_rate": 9.999395316300748e-05,
      "loss": 1.8082,
      "step": 44
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.2003285884857178,
      "learning_rate": 9.999176964288959e-05,
      "loss": 2.1461,
      "step": 45
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.9837427139282227,
      "learning_rate": 9.99892502360984e-05,
      "loss": 1.9401,
      "step": 46
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8116463422775269,
      "learning_rate": 9.99863949595614e-05,
      "loss": 1.8674,
      "step": 47
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.568159341812134,
      "learning_rate": 9.998320383246272e-05,
      "loss": 2.2889,
      "step": 48
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.874122142791748,
      "learning_rate": 9.997967687624303e-05,
      "loss": 1.9151,
      "step": 49
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.098505973815918,
      "learning_rate": 9.997581411459941e-05,
      "loss": 2.0527,
      "step": 50
    },
    {
      "epoch": 0.41,
      "grad_norm": 2.121413230895996,
      "learning_rate": 9.997161557348511e-05,
      "loss": 2.1313,
      "step": 51
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.134842872619629,
      "learning_rate": 9.996708128110947e-05,
      "loss": 1.9325,
      "step": 52
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.842974066734314,
      "learning_rate": 9.996221126793765e-05,
      "loss": 1.8932,
      "step": 53
    },
    {
      "epoch": 0.43,
      "grad_norm": 2.3149209022521973,
      "learning_rate": 9.995700556669052e-05,
      "loss": 2.2002,
      "step": 54
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9193192720413208,
      "learning_rate": 9.995146421234434e-05,
      "loss": 2.0703,
      "step": 55
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.877560019493103,
      "learning_rate": 9.994558724213054e-05,
      "loss": 2.014,
      "step": 56
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.896249771118164,
      "learning_rate": 9.99393746955356e-05,
      "loss": 1.8619,
      "step": 57
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.1330864429473877,
      "learning_rate": 9.993282661430057e-05,
      "loss": 2.0506,
      "step": 58
    },
    {
      "epoch": 0.47,
      "grad_norm": 2.0332887172698975,
      "learning_rate": 9.9925943042421e-05,
      "loss": 2.0515,
      "step": 59
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.85440993309021,
      "learning_rate": 9.991872402614648e-05,
      "loss": 1.8876,
      "step": 60
    },
    {
      "epoch": 0.49,
      "grad_norm": 2.1047351360321045,
      "learning_rate": 9.991116961398043e-05,
      "loss": 1.8301,
      "step": 61
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.3208518028259277,
      "learning_rate": 9.990327985667972e-05,
      "loss": 2.2094,
      "step": 62
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.2598137855529785,
      "learning_rate": 9.989505480725439e-05,
      "loss": 2.2685,
      "step": 63
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.2316479682922363,
      "learning_rate": 9.988649452096718e-05,
      "loss": 2.1507,
      "step": 64
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.920062780380249,
      "learning_rate": 9.987759905533331e-05,
      "loss": 1.9141,
      "step": 65
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.7150771617889404,
      "learning_rate": 9.986836847012e-05,
      "loss": 2.0118,
      "step": 66
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.7101502418518066,
      "learning_rate": 9.985880282734604e-05,
      "loss": 1.5796,
      "step": 67
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9139412641525269,
      "learning_rate": 9.984890219128146e-05,
      "loss": 1.7124,
      "step": 68
    },
    {
      "epoch": 0.55,
      "grad_norm": 2.278245687484741,
      "learning_rate": 9.983866662844705e-05,
      "loss": 2.0703,
      "step": 69
    },
    {
      "epoch": 0.56,
      "grad_norm": 1.9326863288879395,
      "learning_rate": 9.98280962076139e-05,
      "loss": 2.0205,
      "step": 70
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.2788615226745605,
      "learning_rate": 9.981719099980299e-05,
      "loss": 2.1035,
      "step": 71
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.026341438293457,
      "learning_rate": 9.980595107828465e-05,
      "loss": 2.0321,
      "step": 72
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.876949667930603,
      "learning_rate": 9.979437651857808e-05,
      "loss": 1.895,
      "step": 73
    },
    {
      "epoch": 0.59,
      "grad_norm": 2.074075222015381,
      "learning_rate": 9.978246739845094e-05,
      "loss": 1.8401,
      "step": 74
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.2819888591766357,
      "learning_rate": 9.977022379791865e-05,
      "loss": 1.9217,
      "step": 75
    },
    {
      "epoch": 0.61,
      "grad_norm": 2.2832257747650146,
      "learning_rate": 9.975764579924402e-05,
      "loss": 2.031,
      "step": 76
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.3486344814300537,
      "learning_rate": 9.97447334869366e-05,
      "loss": 2.2127,
      "step": 77
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.9454829692840576,
      "learning_rate": 9.973148694775217e-05,
      "loss": 1.9226,
      "step": 78
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.1101129055023193,
      "learning_rate": 9.971790627069204e-05,
      "loss": 1.8037,
      "step": 79
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4301042556762695,
      "learning_rate": 9.970399154700263e-05,
      "loss": 2.1496,
      "step": 80
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.8383513689041138,
      "learning_rate": 9.968974287017474e-05,
      "loss": 1.6823,
      "step": 81
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.0817694664001465,
      "learning_rate": 9.967516033594295e-05,
      "loss": 2.0043,
      "step": 82
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8396806716918945,
      "learning_rate": 9.966024404228495e-05,
      "loss": 1.8017,
      "step": 83
    },
    {
      "epoch": 0.67,
      "grad_norm": 2.116056203842163,
      "learning_rate": 9.964499408942091e-05,
      "loss": 2.0264,
      "step": 84
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0635361671447754,
      "learning_rate": 9.962941057981284e-05,
      "loss": 1.8297,
      "step": 85
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.261688232421875,
      "learning_rate": 9.961349361816384e-05,
      "loss": 2.0307,
      "step": 86
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.136413812637329,
      "learning_rate": 9.959724331141739e-05,
      "loss": 1.8821,
      "step": 87
    },
    {
      "epoch": 0.7,
      "grad_norm": 2.095707416534424,
      "learning_rate": 9.958065976875671e-05,
      "loss": 1.9524,
      "step": 88
    },
    {
      "epoch": 0.71,
      "grad_norm": 2.043297529220581,
      "learning_rate": 9.956374310160397e-05,
      "loss": 1.8108,
      "step": 89
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.8659701347351074,
      "learning_rate": 9.954649342361952e-05,
      "loss": 1.8021,
      "step": 90
    },
    {
      "epoch": 0.73,
      "grad_norm": 2.051514148712158,
      "learning_rate": 9.952891085070119e-05,
      "loss": 2.0815,
      "step": 91
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.177419424057007,
      "learning_rate": 9.951099550098349e-05,
      "loss": 1.7871,
      "step": 92
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.2865824699401855,
      "learning_rate": 9.949274749483671e-05,
      "loss": 2.0838,
      "step": 93
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.133869171142578,
      "learning_rate": 9.947416695486633e-05,
      "loss": 1.9042,
      "step": 94
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.078374147415161,
      "learning_rate": 9.9455254005912e-05,
      "loss": 1.826,
      "step": 95
    },
    {
      "epoch": 0.77,
      "grad_norm": 1.8939728736877441,
      "learning_rate": 9.943600877504678e-05,
      "loss": 1.6378,
      "step": 96
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2477104663848877,
      "learning_rate": 9.941643139157631e-05,
      "loss": 2.1755,
      "step": 97
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1704578399658203,
      "learning_rate": 9.939652198703784e-05,
      "loss": 1.886,
      "step": 98
    },
    {
      "epoch": 0.79,
      "grad_norm": 2.1225337982177734,
      "learning_rate": 9.937628069519951e-05,
      "loss": 1.7013,
      "step": 99
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.288053035736084,
      "learning_rate": 9.935570765205927e-05,
      "loss": 2.1093,
      "step": 100
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.4804885387420654,
      "learning_rate": 9.933480299584413e-05,
      "loss": 2.0892,
      "step": 101
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.419746160507202,
      "learning_rate": 9.93135668670091e-05,
      "loss": 1.9403,
      "step": 102
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.216740369796753,
      "learning_rate": 9.92919994082363e-05,
      "loss": 1.9342,
      "step": 103
    },
    {
      "epoch": 0.83,
      "grad_norm": 2.1508047580718994,
      "learning_rate": 9.927010076443407e-05,
      "loss": 1.954,
      "step": 104
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.6193196773529053,
      "learning_rate": 9.924787108273586e-05,
      "loss": 2.0794,
      "step": 105
    },
    {
      "epoch": 0.85,
      "grad_norm": 2.0855460166931152,
      "learning_rate": 9.92253105124993e-05,
      "loss": 1.8125,
      "step": 106
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2653427124023438,
      "learning_rate": 9.920241920530529e-05,
      "loss": 1.9577,
      "step": 107
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2813096046447754,
      "learning_rate": 9.917919731495681e-05,
      "loss": 1.6701,
      "step": 108
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.5022311210632324,
      "learning_rate": 9.915564499747803e-05,
      "loss": 1.7516,
      "step": 109
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.2967872619628906,
      "learning_rate": 9.913176241111319e-05,
      "loss": 1.7794,
      "step": 110
    },
    {
      "epoch": 0.89,
      "grad_norm": 2.247812271118164,
      "learning_rate": 9.910754971632554e-05,
      "loss": 1.8358,
      "step": 111
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.3595893383026123,
      "learning_rate": 9.908300707579632e-05,
      "loss": 1.9633,
      "step": 112
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.4815473556518555,
      "learning_rate": 9.905813465442356e-05,
      "loss": 1.7839,
      "step": 113
    },
    {
      "epoch": 0.91,
      "grad_norm": 2.126142978668213,
      "learning_rate": 9.903293261932105e-05,
      "loss": 1.7227,
      "step": 114
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.5484907627105713,
      "learning_rate": 9.900740113981725e-05,
      "loss": 1.9721,
      "step": 115
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.603926658630371,
      "learning_rate": 9.898154038745408e-05,
      "loss": 2.1174,
      "step": 116
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.9761155843734741,
      "learning_rate": 9.895535053598577e-05,
      "loss": 1.7614,
      "step": 117
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.1262032985687256,
      "learning_rate": 9.892883176137771e-05,
      "loss": 1.6561,
      "step": 118
    },
    {
      "epoch": 0.95,
      "grad_norm": 1.8068169355392456,
      "learning_rate": 9.89019842418053e-05,
      "loss": 1.5837,
      "step": 119
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.144500732421875,
      "learning_rate": 9.887480815765273e-05,
      "loss": 1.7693,
      "step": 120
    },
    {
      "epoch": 0.97,
      "grad_norm": 2.0845284461975098,
      "learning_rate": 9.88473036915117e-05,
      "loss": 1.7671,
      "step": 121
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.057933807373047,
      "learning_rate": 9.881947102818036e-05,
      "loss": 1.7095,
      "step": 122
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.0968189239501953,
      "learning_rate": 9.879131035466187e-05,
      "loss": 1.6977,
      "step": 123
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.175576686859131,
      "learning_rate": 9.876282186016329e-05,
      "loss": 1.691,
      "step": 124
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.3416388034820557,
      "learning_rate": 9.873400573609421e-05,
      "loss": 1.8571,
      "step": 125
    },
    {
      "epoch": 1.01,
      "grad_norm": 2.2300479412078857,
      "learning_rate": 9.870486217606558e-05,
      "loss": 1.6754,
      "step": 126
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.1028525829315186,
      "learning_rate": 9.867539137588827e-05,
      "loss": 1.4463,
      "step": 127
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.2686033248901367,
      "learning_rate": 9.864559353357187e-05,
      "loss": 1.6322,
      "step": 128
    },
    {
      "epoch": 1.03,
      "grad_norm": 2.199704885482788,
      "learning_rate": 9.861546884932331e-05,
      "loss": 1.7406,
      "step": 129
    },
    {
      "epoch": 1.04,
      "grad_norm": 2.4048664569854736,
      "learning_rate": 9.858501752554547e-05,
      "loss": 1.6994,
      "step": 130
    },
    {
      "epoch": 1.05,
      "grad_norm": 2.1530885696411133,
      "learning_rate": 9.855423976683595e-05,
      "loss": 1.4768,
      "step": 131
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.474882125854492,
      "learning_rate": 9.852313577998554e-05,
      "loss": 1.5372,
      "step": 132
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.9963340759277344,
      "learning_rate": 9.849170577397694e-05,
      "loss": 1.4221,
      "step": 133
    },
    {
      "epoch": 1.07,
      "grad_norm": 2.310929298400879,
      "learning_rate": 9.845994995998332e-05,
      "loss": 1.5752,
      "step": 134
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.422445058822632,
      "learning_rate": 9.842786855136688e-05,
      "loss": 1.5698,
      "step": 135
    },
    {
      "epoch": 1.09,
      "grad_norm": 2.077146530151367,
      "learning_rate": 9.839546176367745e-05,
      "loss": 1.1516,
      "step": 136
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.3803155422210693,
      "learning_rate": 9.836272981465107e-05,
      "loss": 1.4116,
      "step": 137
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.952641725540161,
      "learning_rate": 9.832967292420841e-05,
      "loss": 1.6944,
      "step": 138
    },
    {
      "epoch": 1.11,
      "grad_norm": 2.195828914642334,
      "learning_rate": 9.829629131445342e-05,
      "loss": 1.153,
      "step": 139
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.8987488746643066,
      "learning_rate": 9.826258520967178e-05,
      "loss": 1.36,
      "step": 140
    },
    {
      "epoch": 1.13,
      "grad_norm": 2.835303783416748,
      "learning_rate": 9.822855483632941e-05,
      "loss": 1.5179,
      "step": 141
    },
    {
      "epoch": 1.14,
      "grad_norm": 3.1946606636047363,
      "learning_rate": 9.819420042307091e-05,
      "loss": 1.582,
      "step": 142
    },
    {
      "epoch": 1.14,
      "grad_norm": 2.946847915649414,
      "learning_rate": 9.815952220071806e-05,
      "loss": 1.347,
      "step": 143
    },
    {
      "epoch": 1.15,
      "grad_norm": 3.4186108112335205,
      "learning_rate": 9.812452040226827e-05,
      "loss": 1.8268,
      "step": 144
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.1212668418884277,
      "learning_rate": 9.808919526289302e-05,
      "loss": 1.7198,
      "step": 145
    },
    {
      "epoch": 1.17,
      "grad_norm": 2.919663906097412,
      "learning_rate": 9.805354701993623e-05,
      "loss": 1.7844,
      "step": 146
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.2250006198883057,
      "learning_rate": 9.801757591291274e-05,
      "loss": 1.3294,
      "step": 147
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.845139503479004,
      "learning_rate": 9.798128218350662e-05,
      "loss": 1.825,
      "step": 148
    },
    {
      "epoch": 1.19,
      "grad_norm": 2.499061107635498,
      "learning_rate": 9.794466607556963e-05,
      "loss": 1.4839,
      "step": 149
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.2593181133270264,
      "learning_rate": 9.79077278351195e-05,
      "loss": 1.2066,
      "step": 150
    },
    {
      "epoch": 1.21,
      "grad_norm": 2.473970890045166,
      "learning_rate": 9.787046771033836e-05,
      "loss": 1.3882,
      "step": 151
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.8645358085632324,
      "learning_rate": 9.783288595157098e-05,
      "loss": 1.6684,
      "step": 152
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.8085780143737793,
      "learning_rate": 9.77949828113232e-05,
      "loss": 1.7768,
      "step": 153
    },
    {
      "epoch": 1.23,
      "grad_norm": 2.3986098766326904,
      "learning_rate": 9.77567585442601e-05,
      "loss": 1.4112,
      "step": 154
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.865717887878418,
      "learning_rate": 9.77182134072044e-05,
      "loss": 1.6726,
      "step": 155
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.726743459701538,
      "learning_rate": 9.767934765913469e-05,
      "loss": 1.5786,
      "step": 156
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.145963668823242,
      "learning_rate": 9.764016156118368e-05,
      "loss": 1.7245,
      "step": 157
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.6086299419403076,
      "learning_rate": 9.760065537663649e-05,
      "loss": 1.5252,
      "step": 158
    },
    {
      "epoch": 1.27,
      "grad_norm": 2.3834784030914307,
      "learning_rate": 9.756082937092884e-05,
      "loss": 1.2795,
      "step": 159
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.1744251251220703,
      "learning_rate": 9.752068381164524e-05,
      "loss": 1.381,
      "step": 160
    },
    {
      "epoch": 1.29,
      "grad_norm": 2.698655843734741,
      "learning_rate": 9.748021896851725e-05,
      "loss": 1.7215,
      "step": 161
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.2155649662017822,
      "learning_rate": 9.743943511342168e-05,
      "loss": 1.3931,
      "step": 162
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.18544602394104,
      "learning_rate": 9.739833252037868e-05,
      "loss": 1.3029,
      "step": 163
    },
    {
      "epoch": 1.31,
      "grad_norm": 2.7235467433929443,
      "learning_rate": 9.735691146555002e-05,
      "loss": 1.7729,
      "step": 164
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.539064884185791,
      "learning_rate": 9.731517222723706e-05,
      "loss": 1.2787,
      "step": 165
    },
    {
      "epoch": 1.33,
      "grad_norm": 2.529325246810913,
      "learning_rate": 9.727311508587906e-05,
      "loss": 1.4947,
      "step": 166
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.6471948623657227,
      "learning_rate": 9.723074032405121e-05,
      "loss": 1.5919,
      "step": 167
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.3570592403411865,
      "learning_rate": 9.718804822646273e-05,
      "loss": 1.2661,
      "step": 168
    },
    {
      "epoch": 1.35,
      "grad_norm": 2.871769905090332,
      "learning_rate": 9.714503907995496e-05,
      "loss": 1.4509,
      "step": 169
    },
    {
      "epoch": 1.36,
      "grad_norm": 2.842827320098877,
      "learning_rate": 9.710171317349945e-05,
      "loss": 1.5462,
      "step": 170
    },
    {
      "epoch": 1.37,
      "grad_norm": 2.291958808898926,
      "learning_rate": 9.705807079819602e-05,
      "loss": 1.1163,
      "step": 171
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.6132652759552,
      "learning_rate": 9.701411224727077e-05,
      "loss": 1.3157,
      "step": 172
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.81820011138916,
      "learning_rate": 9.696983781607417e-05,
      "loss": 1.5386,
      "step": 173
    },
    {
      "epoch": 1.39,
      "grad_norm": 2.9998795986175537,
      "learning_rate": 9.692524780207897e-05,
      "loss": 1.5256,
      "step": 174
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.4604580402374268,
      "learning_rate": 9.688034250487833e-05,
      "loss": 1.633,
      "step": 175
    },
    {
      "epoch": 1.41,
      "grad_norm": 2.3979203701019287,
      "learning_rate": 9.683512222618377e-05,
      "loss": 1.2279,
      "step": 176
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.6284639835357666,
      "learning_rate": 9.6789587269823e-05,
      "loss": 1.6481,
      "step": 177
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.5688490867614746,
      "learning_rate": 9.674373794173818e-05,
      "loss": 1.4079,
      "step": 178
    },
    {
      "epoch": 1.43,
      "grad_norm": 2.6544580459594727,
      "learning_rate": 9.669757454998353e-05,
      "loss": 1.6489,
      "step": 179
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.7770259380340576,
      "learning_rate": 9.665109740472347e-05,
      "loss": 1.6828,
      "step": 180
    },
    {
      "epoch": 1.45,
      "grad_norm": 2.7298226356506348,
      "learning_rate": 9.660430681823048e-05,
      "loss": 1.5081,
      "step": 181
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.5638253688812256,
      "learning_rate": 9.655720310488299e-05,
      "loss": 1.57,
      "step": 182
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.467770576477051,
      "learning_rate": 9.650978658116329e-05,
      "loss": 1.3426,
      "step": 183
    },
    {
      "epoch": 1.47,
      "grad_norm": 2.875515937805176,
      "learning_rate": 9.64620575656554e-05,
      "loss": 1.5677,
      "step": 184
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.0199334621429443,
      "learning_rate": 9.64140163790429e-05,
      "loss": 1.7957,
      "step": 185
    },
    {
      "epoch": 1.49,
      "grad_norm": 2.109271287918091,
      "learning_rate": 9.636566334410682e-05,
      "loss": 1.1012,
      "step": 186
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.186971664428711,
      "learning_rate": 9.631699878572342e-05,
      "loss": 1.1529,
      "step": 187
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.4922494888305664,
      "learning_rate": 9.626802303086208e-05,
      "loss": 1.3301,
      "step": 188
    },
    {
      "epoch": 1.51,
      "grad_norm": 2.5560436248779297,
      "learning_rate": 9.6218736408583e-05,
      "loss": 1.2068,
      "step": 189
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.3466458320617676,
      "learning_rate": 9.616913925003513e-05,
      "loss": 1.7692,
      "step": 190
    },
    {
      "epoch": 1.53,
      "grad_norm": 2.690890073776245,
      "learning_rate": 9.611923188845377e-05,
      "loss": 1.4818,
      "step": 191
    },
    {
      "epoch": 1.54,
      "grad_norm": 3.0207912921905518,
      "learning_rate": 9.606901465915848e-05,
      "loss": 1.5221,
      "step": 192
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.9412505626678467,
      "learning_rate": 9.601848789955077e-05,
      "loss": 1.4037,
      "step": 193
    },
    {
      "epoch": 1.55,
      "grad_norm": 2.7496883869171143,
      "learning_rate": 9.596765194911181e-05,
      "loss": 1.6083,
      "step": 194
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.5963120460510254,
      "learning_rate": 9.591650714940021e-05,
      "loss": 1.4911,
      "step": 195
    },
    {
      "epoch": 1.57,
      "grad_norm": 2.7765257358551025,
      "learning_rate": 9.586505384404967e-05,
      "loss": 1.5519,
      "step": 196
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.242443084716797,
      "learning_rate": 9.581329237876664e-05,
      "loss": 1.2288,
      "step": 197
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.6032347679138184,
      "learning_rate": 9.576122310132815e-05,
      "loss": 1.5594,
      "step": 198
    },
    {
      "epoch": 1.59,
      "grad_norm": 1.9934715032577515,
      "learning_rate": 9.570884636157929e-05,
      "loss": 1.0536,
      "step": 199
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.381632089614868,
      "learning_rate": 9.565616251143094e-05,
      "loss": 1.2711,
      "step": 200
    },
    {
      "epoch": 1.61,
      "grad_norm": 2.7006850242614746,
      "learning_rate": 9.560317190485748e-05,
      "loss": 1.3534,
      "step": 201
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.059769630432129,
      "learning_rate": 9.554987489789425e-05,
      "loss": 1.0522,
      "step": 202
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.1919727325439453,
      "learning_rate": 9.54962718486353e-05,
      "loss": 1.4524,
      "step": 203
    },
    {
      "epoch": 1.63,
      "grad_norm": 2.8805959224700928,
      "learning_rate": 9.544236311723092e-05,
      "loss": 1.3412,
      "step": 204
    },
    {
      "epoch": 1.64,
      "grad_norm": 2.666990280151367,
      "learning_rate": 9.538814906588518e-05,
      "loss": 1.3898,
      "step": 205
    },
    {
      "epoch": 1.65,
      "grad_norm": 2.714350461959839,
      "learning_rate": 9.533363005885363e-05,
      "loss": 1.3953,
      "step": 206
    },
    {
      "epoch": 1.66,
      "grad_norm": 2.8577756881713867,
      "learning_rate": 9.527880646244071e-05,
      "loss": 1.4531,
      "step": 207
    },
    {
      "epoch": 1.66,
      "grad_norm": 3.079169750213623,
      "learning_rate": 9.522367864499736e-05,
      "loss": 1.5931,
      "step": 208
    },
    {
      "epoch": 1.67,
      "grad_norm": 2.7736661434173584,
      "learning_rate": 9.516824697691851e-05,
      "loss": 1.3288,
      "step": 209
    },
    {
      "epoch": 1.68,
      "grad_norm": 2.818991184234619,
      "learning_rate": 9.511251183064068e-05,
      "loss": 1.5765,
      "step": 210
    },
    {
      "epoch": 1.69,
      "grad_norm": 2.9158811569213867,
      "learning_rate": 9.505647358063934e-05,
      "loss": 1.4144,
      "step": 211
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.3535475730895996,
      "learning_rate": 9.500013260342651e-05,
      "loss": 1.1144,
      "step": 212
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.3112270832061768,
      "learning_rate": 9.494348927754815e-05,
      "loss": 1.1009,
      "step": 213
    },
    {
      "epoch": 1.71,
      "grad_norm": 2.472301721572876,
      "learning_rate": 9.48865439835817e-05,
      "loss": 1.3823,
      "step": 214
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.692115545272827,
      "learning_rate": 9.482929710413342e-05,
      "loss": 1.3531,
      "step": 215
    },
    {
      "epoch": 1.73,
      "grad_norm": 2.641547203063965,
      "learning_rate": 9.477174902383592e-05,
      "loss": 1.3484,
      "step": 216
    },
    {
      "epoch": 1.74,
      "grad_norm": 3.5799379348754883,
      "learning_rate": 9.471390012934549e-05,
      "loss": 1.4779,
      "step": 217
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.5849697589874268,
      "learning_rate": 9.465575080933958e-05,
      "loss": 1.3181,
      "step": 218
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.972431182861328,
      "learning_rate": 9.459730145451413e-05,
      "loss": 1.6141,
      "step": 219
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.6137802600860596,
      "learning_rate": 9.453855245758099e-05,
      "loss": 1.3246,
      "step": 220
    },
    {
      "epoch": 1.77,
      "grad_norm": 2.166318416595459,
      "learning_rate": 9.44795042132652e-05,
      "loss": 1.2297,
      "step": 221
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.684629201889038,
      "learning_rate": 9.442015711830245e-05,
      "loss": 1.5389,
      "step": 222
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.3157501220703125,
      "learning_rate": 9.436051157143635e-05,
      "loss": 1.2192,
      "step": 223
    },
    {
      "epoch": 1.79,
      "grad_norm": 2.220203399658203,
      "learning_rate": 9.430056797341574e-05,
      "loss": 1.1658,
      "step": 224
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.9631688594818115,
      "learning_rate": 9.424032672699205e-05,
      "loss": 1.5935,
      "step": 225
    },
    {
      "epoch": 1.81,
      "grad_norm": 2.595777750015259,
      "learning_rate": 9.417978823691651e-05,
      "loss": 1.5184,
      "step": 226
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.2303333282470703,
      "learning_rate": 9.411895290993754e-05,
      "loss": 1.1982,
      "step": 227
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.183046817779541,
      "learning_rate": 9.405782115479794e-05,
      "loss": 1.1177,
      "step": 228
    },
    {
      "epoch": 1.83,
      "grad_norm": 2.7798430919647217,
      "learning_rate": 9.399639338223212e-05,
      "loss": 1.4545,
      "step": 229
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.8518762588500977,
      "learning_rate": 9.393467000496344e-05,
      "loss": 1.5469,
      "step": 230
    },
    {
      "epoch": 1.85,
      "grad_norm": 2.750490665435791,
      "learning_rate": 9.387265143770139e-05,
      "loss": 1.6536,
      "step": 231
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.260718584060669,
      "learning_rate": 9.381033809713873e-05,
      "loss": 1.146,
      "step": 232
    },
    {
      "epoch": 1.86,
      "grad_norm": 2.836858034133911,
      "learning_rate": 9.374773040194878e-05,
      "loss": 1.4612,
      "step": 233
    },
    {
      "epoch": 1.87,
      "grad_norm": 2.5010712146759033,
      "learning_rate": 9.368482877278264e-05,
      "loss": 1.2653,
      "step": 234
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.59248685836792,
      "learning_rate": 9.362163363226622e-05,
      "loss": 1.5484,
      "step": 235
    },
    {
      "epoch": 1.89,
      "grad_norm": 2.6382546424865723,
      "learning_rate": 9.355814540499752e-05,
      "loss": 1.1426,
      "step": 236
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.436722755432129,
      "learning_rate": 9.349436451754378e-05,
      "loss": 1.6047,
      "step": 237
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.3625075817108154,
      "learning_rate": 9.343029139843849e-05,
      "loss": 1.0766,
      "step": 238
    },
    {
      "epoch": 1.91,
      "grad_norm": 2.9357194900512695,
      "learning_rate": 9.33659264781787e-05,
      "loss": 1.2845,
      "step": 239
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.107611656188965,
      "learning_rate": 9.330127018922194e-05,
      "loss": 1.3917,
      "step": 240
    },
    {
      "epoch": 1.93,
      "grad_norm": 3.429243564605713,
      "learning_rate": 9.323632296598344e-05,
      "loss": 1.6156,
      "step": 241
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.1010968685150146,
      "learning_rate": 9.317108524483318e-05,
      "loss": 1.3044,
      "step": 242
    },
    {
      "epoch": 1.94,
      "grad_norm": 2.9426207542419434,
      "learning_rate": 9.310555746409292e-05,
      "loss": 1.2145,
      "step": 243
    },
    {
      "epoch": 1.95,
      "grad_norm": 2.561343193054199,
      "learning_rate": 9.30397400640333e-05,
      "loss": 1.2789,
      "step": 244
    },
    {
      "epoch": 1.96,
      "grad_norm": 3.3198747634887695,
      "learning_rate": 9.297363348687088e-05,
      "loss": 1.5777,
      "step": 245
    },
    {
      "epoch": 1.97,
      "grad_norm": 2.974390983581543,
      "learning_rate": 9.29072381767651e-05,
      "loss": 1.4087,
      "step": 246
    },
    {
      "epoch": 1.98,
      "grad_norm": 2.880276918411255,
      "learning_rate": 9.28405545798154e-05,
      "loss": 1.358,
      "step": 247
    },
    {
      "epoch": 1.98,
      "grad_norm": 2.832646131515503,
      "learning_rate": 9.27735831440582e-05,
      "loss": 1.6127,
      "step": 248
    },
    {
      "epoch": 1.99,
      "grad_norm": 2.875298261642456,
      "learning_rate": 9.270632431946377e-05,
      "loss": 1.5964,
      "step": 249
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.8396198749542236,
      "learning_rate": 9.263877855793339e-05,
      "loss": 1.6769,
      "step": 250
    },
    {
      "epoch": 2.01,
      "grad_norm": 2.276285409927368,
      "learning_rate": 9.257094631329617e-05,
      "loss": 1.014,
      "step": 251
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.204651117324829,
      "learning_rate": 9.250282804130607e-05,
      "loss": 1.1136,
      "step": 252
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.1509318351745605,
      "learning_rate": 9.243442419963884e-05,
      "loss": 0.9715,
      "step": 253
    },
    {
      "epoch": 2.03,
      "grad_norm": 2.3302001953125,
      "learning_rate": 9.236573524788887e-05,
      "loss": 1.1375,
      "step": 254
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.245983600616455,
      "learning_rate": 9.229676164756625e-05,
      "loss": 0.903,
      "step": 255
    },
    {
      "epoch": 2.05,
      "grad_norm": 2.6309142112731934,
      "learning_rate": 9.222750386209348e-05,
      "loss": 1.1644,
      "step": 256
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.0632598400115967,
      "learning_rate": 9.215796235680252e-05,
      "loss": 1.1549,
      "step": 257
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.0214059352874756,
      "learning_rate": 9.208813759893157e-05,
      "loss": 1.1182,
      "step": 258
    },
    {
      "epoch": 2.07,
      "grad_norm": 2.7231833934783936,
      "learning_rate": 9.2018030057622e-05,
      "loss": 1.0307,
      "step": 259
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.183375358581543,
      "learning_rate": 9.194764020391506e-05,
      "loss": 0.7758,
      "step": 260
    },
    {
      "epoch": 2.09,
      "grad_norm": 2.984064817428589,
      "learning_rate": 9.187696851074893e-05,
      "loss": 0.9326,
      "step": 261
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.309386968612671,
      "learning_rate": 9.180601545295536e-05,
      "loss": 1.1108,
      "step": 262
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.0485281944274902,
      "learning_rate": 9.173478150725652e-05,
      "loss": 0.8551,
      "step": 263
    },
    {
      "epoch": 2.11,
      "grad_norm": 2.5908138751983643,
      "learning_rate": 9.166326715226188e-05,
      "loss": 0.7215,
      "step": 264
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.987614393234253,
      "learning_rate": 9.159147286846492e-05,
      "loss": 0.9419,
      "step": 265
    },
    {
      "epoch": 2.13,
      "grad_norm": 2.6122493743896484,
      "learning_rate": 9.151939913823988e-05,
      "loss": 0.8977,
      "step": 266
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.8692774772644043,
      "learning_rate": 9.14470464458386e-05,
      "loss": 0.9562,
      "step": 267
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.8896327018737793,
      "learning_rate": 9.137441527738718e-05,
      "loss": 0.9777,
      "step": 268
    },
    {
      "epoch": 2.15,
      "grad_norm": 3.0123207569122314,
      "learning_rate": 9.130150612088279e-05,
      "loss": 0.9907,
      "step": 269
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.026132106781006,
      "learning_rate": 9.122831946619037e-05,
      "loss": 1.1195,
      "step": 270
    },
    {
      "epoch": 2.17,
      "grad_norm": 3.133664846420288,
      "learning_rate": 9.115485580503926e-05,
      "loss": 0.9577,
      "step": 271
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.86942458152771,
      "learning_rate": 9.108111563102004e-05,
      "loss": 1.2416,
      "step": 272
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.981334686279297,
      "learning_rate": 9.100709943958107e-05,
      "loss": 0.995,
      "step": 273
    },
    {
      "epoch": 2.19,
      "grad_norm": 2.7346158027648926,
      "learning_rate": 9.093280772802527e-05,
      "loss": 0.8846,
      "step": 274
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.467487335205078,
      "learning_rate": 9.085824099550673e-05,
      "loss": 0.7133,
      "step": 275
    },
    {
      "epoch": 2.21,
      "grad_norm": 2.8115592002868652,
      "learning_rate": 9.078339974302734e-05,
      "loss": 0.9187,
      "step": 276
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.868636131286621,
      "learning_rate": 9.070828447343344e-05,
      "loss": 0.9111,
      "step": 277
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.3456575870513916,
      "learning_rate": 9.063289569141251e-05,
      "loss": 1.2465,
      "step": 278
    },
    {
      "epoch": 2.23,
      "grad_norm": 2.8516812324523926,
      "learning_rate": 9.055723390348964e-05,
      "loss": 0.8353,
      "step": 279
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.9438064098358154,
      "learning_rate": 9.048129961802426e-05,
      "loss": 1.077,
      "step": 280
    },
    {
      "epoch": 2.25,
      "grad_norm": 2.9745640754699707,
      "learning_rate": 9.040509334520662e-05,
      "loss": 0.8804,
      "step": 281
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.601365804672241,
      "learning_rate": 9.032861559705442e-05,
      "loss": 0.8499,
      "step": 282
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.8689122200012207,
      "learning_rate": 9.025186688740939e-05,
      "loss": 1.0773,
      "step": 283
    },
    {
      "epoch": 2.27,
      "grad_norm": 2.728534698486328,
      "learning_rate": 9.017484773193378e-05,
      "loss": 1.0238,
      "step": 284
    },
    {
      "epoch": 2.28,
      "grad_norm": 2.933967113494873,
      "learning_rate": 9.009755864810696e-05,
      "loss": 0.9951,
      "step": 285
    },
    {
      "epoch": 2.29,
      "grad_norm": 2.4514496326446533,
      "learning_rate": 9.00200001552218e-05,
      "loss": 0.8388,
      "step": 286
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.373528242111206,
      "learning_rate": 8.994217277438144e-05,
      "loss": 1.0544,
      "step": 287
    },
    {
      "epoch": 2.3,
      "grad_norm": 2.4270710945129395,
      "learning_rate": 8.986407702849551e-05,
      "loss": 0.8555,
      "step": 288
    },
    {
      "epoch": 2.31,
      "grad_norm": 2.5846474170684814,
      "learning_rate": 8.978571344227681e-05,
      "loss": 0.7932,
      "step": 289
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.8051204681396484,
      "learning_rate": 8.970708254223768e-05,
      "loss": 0.8597,
      "step": 290
    },
    {
      "epoch": 2.33,
      "grad_norm": 2.5266032218933105,
      "learning_rate": 8.962818485668652e-05,
      "loss": 0.7719,
      "step": 291
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.106102705001831,
      "learning_rate": 8.95490209157242e-05,
      "loss": 1.1204,
      "step": 292
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.593950033187866,
      "learning_rate": 8.946959125124052e-05,
      "loss": 0.8612,
      "step": 293
    },
    {
      "epoch": 2.35,
      "grad_norm": 3.3443477153778076,
      "learning_rate": 8.938989639691067e-05,
      "loss": 1.2035,
      "step": 294
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.7025082111358643,
      "learning_rate": 8.930993688819156e-05,
      "loss": 1.3191,
      "step": 295
    },
    {
      "epoch": 2.37,
      "grad_norm": 3.0541610717773438,
      "learning_rate": 8.92297132623183e-05,
      "loss": 1.0815,
      "step": 296
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.7879042625427246,
      "learning_rate": 8.914922605830055e-05,
      "loss": 0.9089,
      "step": 297
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.672436475753784,
      "learning_rate": 8.90684758169189e-05,
      "loss": 0.898,
      "step": 298
    },
    {
      "epoch": 2.39,
      "grad_norm": 2.1060450077056885,
      "learning_rate": 8.898746308072128e-05,
      "loss": 0.6536,
      "step": 299
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.124443531036377,
      "learning_rate": 8.890618839401924e-05,
      "loss": 0.9955,
      "step": 300
    },
    {
      "epoch": 2.41,
      "grad_norm": 3.0270323753356934,
      "learning_rate": 8.882465230288433e-05,
      "loss": 1.1344,
      "step": 301
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.777189016342163,
      "learning_rate": 8.87428553551445e-05,
      "loss": 0.9303,
      "step": 302
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.493337392807007,
      "learning_rate": 8.866079810038027e-05,
      "loss": 0.7874,
      "step": 303
    },
    {
      "epoch": 2.43,
      "grad_norm": 3.1687164306640625,
      "learning_rate": 8.857848108992117e-05,
      "loss": 1.2583,
      "step": 304
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.997662305831909,
      "learning_rate": 8.849590487684198e-05,
      "loss": 1.1659,
      "step": 305
    },
    {
      "epoch": 2.45,
      "grad_norm": 3.0408546924591064,
      "learning_rate": 8.841307001595904e-05,
      "loss": 0.9902,
      "step": 306
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.4377150535583496,
      "learning_rate": 8.832997706382643e-05,
      "loss": 0.7965,
      "step": 307
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.7912235260009766,
      "learning_rate": 8.824662657873239e-05,
      "loss": 0.9272,
      "step": 308
    },
    {
      "epoch": 2.47,
      "grad_norm": 2.8326408863067627,
      "learning_rate": 8.816301912069543e-05,
      "loss": 0.998,
      "step": 309
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.8972043991088867,
      "learning_rate": 8.807915525146065e-05,
      "loss": 0.8665,
      "step": 310
    },
    {
      "epoch": 2.49,
      "grad_norm": 2.5673739910125732,
      "learning_rate": 8.79950355344959e-05,
      "loss": 0.8542,
      "step": 311
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.164513349533081,
      "learning_rate": 8.791066053498808e-05,
      "loss": 1.2216,
      "step": 312
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.109403610229492,
      "learning_rate": 8.782603081983923e-05,
      "loss": 1.4253,
      "step": 313
    },
    {
      "epoch": 2.51,
      "grad_norm": 2.761608123779297,
      "learning_rate": 8.774114695766286e-05,
      "loss": 0.8837,
      "step": 314
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.728372812271118,
      "learning_rate": 8.765600951877997e-05,
      "loss": 0.8115,
      "step": 315
    },
    {
      "epoch": 2.53,
      "grad_norm": 3.1668901443481445,
      "learning_rate": 8.757061907521537e-05,
      "loss": 1.1895,
      "step": 316
    },
    {
      "epoch": 2.54,
      "grad_norm": 3.1501595973968506,
      "learning_rate": 8.748497620069372e-05,
      "loss": 1.1222,
      "step": 317
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.5436015129089355,
      "learning_rate": 8.739908147063576e-05,
      "loss": 0.8833,
      "step": 318
    },
    {
      "epoch": 2.55,
      "grad_norm": 3.201066493988037,
      "learning_rate": 8.731293546215437e-05,
      "loss": 1.2623,
      "step": 319
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.662757158279419,
      "learning_rate": 8.722653875405075e-05,
      "loss": 0.9386,
      "step": 320
    },
    {
      "epoch": 2.57,
      "grad_norm": 2.310816526412964,
      "learning_rate": 8.713989192681056e-05,
      "loss": 0.7796,
      "step": 321
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.9372284412384033,
      "learning_rate": 8.705299556259985e-05,
      "loss": 0.9689,
      "step": 322
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.257772922515869,
      "learning_rate": 8.696585024526135e-05,
      "loss": 1.2422,
      "step": 323
    },
    {
      "epoch": 2.59,
      "grad_norm": 2.4094746112823486,
      "learning_rate": 8.68784565603105e-05,
      "loss": 0.9177,
      "step": 324
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.096440315246582,
      "learning_rate": 8.679081509493141e-05,
      "loss": 1.1607,
      "step": 325
    },
    {
      "epoch": 2.61,
      "grad_norm": 2.7879347801208496,
      "learning_rate": 8.670292643797302e-05,
      "loss": 0.9524,
      "step": 326
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.6194796562194824,
      "learning_rate": 8.661479117994508e-05,
      "loss": 0.9644,
      "step": 327
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.9309582710266113,
      "learning_rate": 8.652640991301425e-05,
      "loss": 1.0958,
      "step": 328
    },
    {
      "epoch": 2.63,
      "grad_norm": 3.0157032012939453,
      "learning_rate": 8.643778323100009e-05,
      "loss": 1.2151,
      "step": 329
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.928189277648926,
      "learning_rate": 8.634891172937102e-05,
      "loss": 1.1017,
      "step": 330
    },
    {
      "epoch": 2.65,
      "grad_norm": 2.175509452819824,
      "learning_rate": 8.625979600524042e-05,
      "loss": 0.7452,
      "step": 331
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.2200632095336914,
      "learning_rate": 8.617043665736249e-05,
      "loss": 0.7144,
      "step": 332
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.012101173400879,
      "learning_rate": 8.608083428612837e-05,
      "loss": 1.0086,
      "step": 333
    },
    {
      "epoch": 2.67,
      "grad_norm": 2.5856473445892334,
      "learning_rate": 8.599098949356202e-05,
      "loss": 1.0523,
      "step": 334
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.456054210662842,
      "learning_rate": 8.590090288331614e-05,
      "loss": 0.7341,
      "step": 335
    },
    {
      "epoch": 2.69,
      "grad_norm": 2.550605058670044,
      "learning_rate": 8.581057506066821e-05,
      "loss": 0.9533,
      "step": 336
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.2077958583831787,
      "learning_rate": 8.572000663251637e-05,
      "loss": 0.7659,
      "step": 337
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.6110222339630127,
      "learning_rate": 8.562919820737536e-05,
      "loss": 0.8619,
      "step": 338
    },
    {
      "epoch": 2.71,
      "grad_norm": 3.014242172241211,
      "learning_rate": 8.553815039537239e-05,
      "loss": 0.935,
      "step": 339
    },
    {
      "epoch": 2.72,
      "grad_norm": 3.7989723682403564,
      "learning_rate": 8.544686380824308e-05,
      "loss": 1.2021,
      "step": 340
    },
    {
      "epoch": 2.73,
      "grad_norm": 2.7335612773895264,
      "learning_rate": 8.535533905932738e-05,
      "loss": 0.9323,
      "step": 341
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.210017204284668,
      "learning_rate": 8.526357676356537e-05,
      "loss": 1.1235,
      "step": 342
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.928258180618286,
      "learning_rate": 8.517157753749317e-05,
      "loss": 0.9179,
      "step": 343
    },
    {
      "epoch": 2.75,
      "grad_norm": 3.067068099975586,
      "learning_rate": 8.507934199923884e-05,
      "loss": 1.0366,
      "step": 344
    },
    {
      "epoch": 2.76,
      "grad_norm": 2.815253734588623,
      "learning_rate": 8.498687076851813e-05,
      "loss": 0.9279,
      "step": 345
    },
    {
      "epoch": 2.77,
      "grad_norm": 2.7290995121002197,
      "learning_rate": 8.489416446663037e-05,
      "loss": 0.8507,
      "step": 346
    },
    {
      "epoch": 2.78,
      "grad_norm": 2.842461347579956,
      "learning_rate": 8.480122371645434e-05,
      "loss": 0.7872,
      "step": 347
    },
    {
      "epoch": 2.78,
      "grad_norm": 3.1038365364074707,
      "learning_rate": 8.470804914244404e-05,
      "loss": 1.2155,
      "step": 348
    },
    {
      "epoch": 2.79,
      "grad_norm": 2.6006062030792236,
      "learning_rate": 8.461464137062443e-05,
      "loss": 0.896,
      "step": 349
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.836918354034424,
      "learning_rate": 8.452100102858734e-05,
      "loss": 0.8454,
      "step": 350
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.521094799041748,
      "learning_rate": 8.442712874548722e-05,
      "loss": 0.9462,
      "step": 351
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.5607290267944336,
      "learning_rate": 8.433302515203685e-05,
      "loss": 0.932,
      "step": 352
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.3775811195373535,
      "learning_rate": 8.423869088050316e-05,
      "loss": 0.9162,
      "step": 353
    },
    {
      "epoch": 2.83,
      "grad_norm": 2.8282134532928467,
      "learning_rate": 8.414412656470296e-05,
      "loss": 0.9403,
      "step": 354
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.6833412647247314,
      "learning_rate": 8.404933283999875e-05,
      "loss": 0.9565,
      "step": 355
    },
    {
      "epoch": 2.85,
      "grad_norm": 2.6506364345550537,
      "learning_rate": 8.39543103432943e-05,
      "loss": 0.9454,
      "step": 356
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.4401652812957764,
      "learning_rate": 8.385905971303054e-05,
      "loss": 0.7661,
      "step": 357
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.6632444858551025,
      "learning_rate": 8.376358158918114e-05,
      "loss": 0.9635,
      "step": 358
    },
    {
      "epoch": 2.87,
      "grad_norm": 2.347796678543091,
      "learning_rate": 8.366787661324828e-05,
      "loss": 0.6412,
      "step": 359
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.39806866645813,
      "learning_rate": 8.357194542825835e-05,
      "loss": 0.8183,
      "step": 360
    },
    {
      "epoch": 2.89,
      "grad_norm": 2.4372782707214355,
      "learning_rate": 8.347578867875757e-05,
      "loss": 0.7555,
      "step": 361
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.3899009227752686,
      "learning_rate": 8.337940701080768e-05,
      "loss": 1.2604,
      "step": 362
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.8492510318756104,
      "learning_rate": 8.328280107198165e-05,
      "loss": 0.8681,
      "step": 363
    },
    {
      "epoch": 2.91,
      "grad_norm": 2.914334535598755,
      "learning_rate": 8.31859715113593e-05,
      "loss": 1.1805,
      "step": 364
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.670954942703247,
      "learning_rate": 8.308891897952282e-05,
      "loss": 0.82,
      "step": 365
    },
    {
      "epoch": 2.93,
      "grad_norm": 2.3936243057250977,
      "learning_rate": 8.299164412855267e-05,
      "loss": 0.8167,
      "step": 366
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.915997266769409,
      "learning_rate": 8.289414761202292e-05,
      "loss": 1.0843,
      "step": 367
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.8174617290496826,
      "learning_rate": 8.2796430084997e-05,
      "loss": 0.7916,
      "step": 368
    },
    {
      "epoch": 2.95,
      "grad_norm": 2.9749510288238525,
      "learning_rate": 8.269849220402331e-05,
      "loss": 0.9927,
      "step": 369
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.2029874324798584,
      "learning_rate": 8.260033462713072e-05,
      "loss": 0.6451,
      "step": 370
    },
    {
      "epoch": 2.97,
      "grad_norm": 3.499807596206665,
      "learning_rate": 8.250195801382425e-05,
      "loss": 1.0465,
      "step": 371
    },
    {
      "epoch": 2.98,
      "grad_norm": 2.4380738735198975,
      "learning_rate": 8.240336302508055e-05,
      "loss": 0.7469,
      "step": 372
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.2234623432159424,
      "learning_rate": 8.230455032334355e-05,
      "loss": 1.0315,
      "step": 373
    },
    {
      "epoch": 2.99,
      "grad_norm": 3.029340982437134,
      "learning_rate": 8.22055205725199e-05,
      "loss": 1.0479,
      "step": 374
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.9633240699768066,
      "learning_rate": 8.210627443797459e-05,
      "loss": 1.1138,
      "step": 375
    },
    {
      "epoch": 3.01,
      "grad_norm": 2.1157724857330322,
      "learning_rate": 8.200681258652648e-05,
      "loss": 0.5308,
      "step": 376
    },
    {
      "epoch": 3.02,
      "grad_norm": 1.6849297285079956,
      "learning_rate": 8.190713568644377e-05,
      "loss": 0.4798,
      "step": 377
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.38358998298645,
      "learning_rate": 8.180724440743957e-05,
      "loss": 0.632,
      "step": 378
    },
    {
      "epoch": 3.03,
      "grad_norm": 2.1866586208343506,
      "learning_rate": 8.17071394206673e-05,
      "loss": 0.6686,
      "step": 379
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.1064469814300537,
      "learning_rate": 8.160682139871633e-05,
      "loss": 0.7204,
      "step": 380
    },
    {
      "epoch": 3.05,
      "grad_norm": 2.276820182800293,
      "learning_rate": 8.150629101560731e-05,
      "loss": 0.5766,
      "step": 381
    },
    {
      "epoch": 3.06,
      "grad_norm": 2.8871383666992188,
      "learning_rate": 8.14055489467878e-05,
      "loss": 0.807,
      "step": 382
    },
    {
      "epoch": 3.06,
      "grad_norm": 2.389707326889038,
      "learning_rate": 8.130459586912754e-05,
      "loss": 0.6037,
      "step": 383
    },
    {
      "epoch": 3.07,
      "grad_norm": 2.1868298053741455,
      "learning_rate": 8.120343246091402e-05,
      "loss": 0.5702,
      "step": 384
    },
    {
      "epoch": 3.08,
      "grad_norm": 2.8944029808044434,
      "learning_rate": 8.110205940184801e-05,
      "loss": 0.7262,
      "step": 385
    },
    {
      "epoch": 3.09,
      "grad_norm": 3.3298962116241455,
      "learning_rate": 8.100047737303877e-05,
      "loss": 0.8959,
      "step": 386
    },
    {
      "epoch": 3.1,
      "grad_norm": 2.1871235370635986,
      "learning_rate": 8.089868705699963e-05,
      "loss": 0.4889,
      "step": 387
    },
    {
      "epoch": 3.1,
      "grad_norm": 2.096219301223755,
      "learning_rate": 8.079668913764342e-05,
      "loss": 0.5164,
      "step": 388
    },
    {
      "epoch": 3.11,
      "grad_norm": 2.2779765129089355,
      "learning_rate": 8.069448430027778e-05,
      "loss": 0.644,
      "step": 389
    },
    {
      "epoch": 3.12,
      "grad_norm": 2.7575926780700684,
      "learning_rate": 8.059207323160056e-05,
      "loss": 0.5836,
      "step": 390
    },
    {
      "epoch": 3.13,
      "grad_norm": 2.577526330947876,
      "learning_rate": 8.048945661969531e-05,
      "loss": 0.6989,
      "step": 391
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.3339972496032715,
      "learning_rate": 8.03866351540266e-05,
      "loss": 0.5987,
      "step": 392
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.471705436706543,
      "learning_rate": 8.028360952543528e-05,
      "loss": 0.5851,
      "step": 393
    },
    {
      "epoch": 3.15,
      "grad_norm": 2.93854022026062,
      "learning_rate": 8.018038042613407e-05,
      "loss": 0.7002,
      "step": 394
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.634439706802368,
      "learning_rate": 8.007694854970269e-05,
      "loss": 0.7307,
      "step": 395
    },
    {
      "epoch": 3.17,
      "grad_norm": 1.6608418226242065,
      "learning_rate": 7.99733145910833e-05,
      "loss": 0.4502,
      "step": 396
    },
    {
      "epoch": 3.18,
      "grad_norm": 1.8908518552780151,
      "learning_rate": 7.986947924657585e-05,
      "loss": 0.5171,
      "step": 397
    },
    {
      "epoch": 3.18,
      "grad_norm": 2.7833588123321533,
      "learning_rate": 7.97654432138333e-05,
      "loss": 0.7343,
      "step": 398
    },
    {
      "epoch": 3.19,
      "grad_norm": 2.607496500015259,
      "learning_rate": 7.96612071918571e-05,
      "loss": 0.7246,
      "step": 399
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.5580854415893555,
      "learning_rate": 7.955677188099235e-05,
      "loss": 0.5389,
      "step": 400
    },
    {
      "epoch": 3.21,
      "grad_norm": 2.3880679607391357,
      "learning_rate": 7.945213798292309e-05,
      "loss": 0.53,
      "step": 401
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.8643243312835693,
      "learning_rate": 7.93473062006677e-05,
      "loss": 0.7443,
      "step": 402
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.7534894943237305,
      "learning_rate": 7.924227723857411e-05,
      "loss": 0.6465,
      "step": 403
    },
    {
      "epoch": 3.23,
      "grad_norm": 2.6421446800231934,
      "learning_rate": 7.913705180231505e-05,
      "loss": 0.5941,
      "step": 404
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.8543930053710938,
      "learning_rate": 7.903163059888331e-05,
      "loss": 0.7403,
      "step": 405
    },
    {
      "epoch": 3.25,
      "grad_norm": 3.0085554122924805,
      "learning_rate": 7.892601433658704e-05,
      "loss": 0.6962,
      "step": 406
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.780721426010132,
      "learning_rate": 7.882020372504494e-05,
      "loss": 0.7692,
      "step": 407
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.563831329345703,
      "learning_rate": 7.871419947518152e-05,
      "loss": 0.6018,
      "step": 408
    },
    {
      "epoch": 3.27,
      "grad_norm": 2.4052658081054688,
      "learning_rate": 7.860800229922234e-05,
      "loss": 0.5827,
      "step": 409
    },
    {
      "epoch": 3.28,
      "grad_norm": 1.947363018989563,
      "learning_rate": 7.850161291068913e-05,
      "loss": 0.4644,
      "step": 410
    },
    {
      "epoch": 3.29,
      "grad_norm": 2.798842668533325,
      "learning_rate": 7.839503202439516e-05,
      "loss": 0.7299,
      "step": 411
    },
    {
      "epoch": 3.3,
      "grad_norm": 2.2092041969299316,
      "learning_rate": 7.828826035644024e-05,
      "loss": 0.5195,
      "step": 412
    },
    {
      "epoch": 3.3,
      "grad_norm": 2.7013168334960938,
      "learning_rate": 7.818129862420611e-05,
      "loss": 0.6625,
      "step": 413
    },
    {
      "epoch": 3.31,
      "grad_norm": 2.5679049491882324,
      "learning_rate": 7.807414754635145e-05,
      "loss": 0.6878,
      "step": 414
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.9751595258712769,
      "learning_rate": 7.796680784280714e-05,
      "loss": 0.502,
      "step": 415
    },
    {
      "epoch": 3.33,
      "grad_norm": 2.6021902561187744,
      "learning_rate": 7.785928023477142e-05,
      "loss": 0.5936,
      "step": 416
    },
    {
      "epoch": 3.34,
      "grad_norm": 2.6123745441436768,
      "learning_rate": 7.775156544470505e-05,
      "loss": 0.7721,
      "step": 417
    },
    {
      "epoch": 3.34,
      "grad_norm": 2.7310993671417236,
      "learning_rate": 7.764366419632636e-05,
      "loss": 0.7011,
      "step": 418
    },
    {
      "epoch": 3.35,
      "grad_norm": 3.0101542472839355,
      "learning_rate": 7.753557721460655e-05,
      "loss": 0.7947,
      "step": 419
    },
    {
      "epoch": 3.36,
      "grad_norm": 2.288067102432251,
      "learning_rate": 7.74273052257647e-05,
      "loss": 0.5316,
      "step": 420
    },
    {
      "epoch": 3.37,
      "grad_norm": 2.463503122329712,
      "learning_rate": 7.731884895726287e-05,
      "loss": 0.5679,
      "step": 421
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.200631618499756,
      "learning_rate": 7.721020913780137e-05,
      "loss": 0.5253,
      "step": 422
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.7238776683807373,
      "learning_rate": 7.710138649731368e-05,
      "loss": 0.695,
      "step": 423
    },
    {
      "epoch": 3.39,
      "grad_norm": 2.3474299907684326,
      "learning_rate": 7.699238176696161e-05,
      "loss": 0.5612,
      "step": 424
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.5297393798828125,
      "learning_rate": 7.688319567913053e-05,
      "loss": 0.6268,
      "step": 425
    },
    {
      "epoch": 3.41,
      "grad_norm": 2.6803784370422363,
      "learning_rate": 7.677382896742417e-05,
      "loss": 0.5848,
      "step": 426
    },
    {
      "epoch": 3.42,
      "grad_norm": 3.401010274887085,
      "learning_rate": 7.666428236665989e-05,
      "loss": 0.7408,
      "step": 427
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.557347059249878,
      "learning_rate": 7.655455661286376e-05,
      "loss": 0.6004,
      "step": 428
    },
    {
      "epoch": 3.43,
      "grad_norm": 2.7366814613342285,
      "learning_rate": 7.644465244326547e-05,
      "loss": 0.7198,
      "step": 429
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.503746747970581,
      "learning_rate": 7.63345705962935e-05,
      "loss": 0.6263,
      "step": 430
    },
    {
      "epoch": 3.45,
      "grad_norm": 2.457164764404297,
      "learning_rate": 7.62243118115701e-05,
      "loss": 0.6387,
      "step": 431
    },
    {
      "epoch": 3.46,
      "grad_norm": 3.0939581394195557,
      "learning_rate": 7.611387682990637e-05,
      "loss": 0.7958,
      "step": 432
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.3392958641052246,
      "learning_rate": 7.600326639329716e-05,
      "loss": 0.5068,
      "step": 433
    },
    {
      "epoch": 3.47,
      "grad_norm": 2.650517463684082,
      "learning_rate": 7.589248124491627e-05,
      "loss": 0.6972,
      "step": 434
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.8004282712936401,
      "learning_rate": 7.578152212911133e-05,
      "loss": 0.3993,
      "step": 435
    },
    {
      "epoch": 3.49,
      "grad_norm": 1.8628422021865845,
      "learning_rate": 7.567038979139882e-05,
      "loss": 0.4697,
      "step": 436
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.6558890342712402,
      "learning_rate": 7.555908497845904e-05,
      "loss": 0.7608,
      "step": 437
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.4352779388427734,
      "learning_rate": 7.544760843813122e-05,
      "loss": 0.5301,
      "step": 438
    },
    {
      "epoch": 3.51,
      "grad_norm": 2.7154598236083984,
      "learning_rate": 7.533596091940829e-05,
      "loss": 0.6268,
      "step": 439
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.2352445125579834,
      "learning_rate": 7.5224143172432e-05,
      "loss": 0.5092,
      "step": 440
    },
    {
      "epoch": 3.53,
      "grad_norm": 2.1634819507598877,
      "learning_rate": 7.511215594848784e-05,
      "loss": 0.5376,
      "step": 441
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.150071382522583,
      "learning_rate": 7.500000000000001e-05,
      "loss": 0.5783,
      "step": 442
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.709541082382202,
      "learning_rate": 7.48876760805263e-05,
      "loss": 0.5464,
      "step": 443
    },
    {
      "epoch": 3.55,
      "grad_norm": 3.175607442855835,
      "learning_rate": 7.477518494475309e-05,
      "loss": 0.8757,
      "step": 444
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.8567347526550293,
      "learning_rate": 7.466252734849026e-05,
      "loss": 0.6775,
      "step": 445
    },
    {
      "epoch": 3.57,
      "grad_norm": 1.353074550628662,
      "learning_rate": 7.454970404866611e-05,
      "loss": 0.3171,
      "step": 446
    },
    {
      "epoch": 3.58,
      "grad_norm": 2.876917600631714,
      "learning_rate": 7.44367158033223e-05,
      "loss": 0.6009,
      "step": 447
    },
    {
      "epoch": 3.58,
      "grad_norm": 2.1507394313812256,
      "learning_rate": 7.432356337160867e-05,
      "loss": 0.4882,
      "step": 448
    },
    {
      "epoch": 3.59,
      "grad_norm": 1.8098483085632324,
      "learning_rate": 7.421024751377825e-05,
      "loss": 0.3995,
      "step": 449
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.101771354675293,
      "learning_rate": 7.409676899118214e-05,
      "loss": 0.7557,
      "step": 450
    },
    {
      "epoch": 3.61,
      "grad_norm": 2.7530267238616943,
      "learning_rate": 7.398312856626424e-05,
      "loss": 0.6869,
      "step": 451
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.5247862339019775,
      "learning_rate": 7.386932700255636e-05,
      "loss": 0.5656,
      "step": 452
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.4389989376068115,
      "learning_rate": 7.375536506467294e-05,
      "loss": 0.4844,
      "step": 453
    },
    {
      "epoch": 3.63,
      "grad_norm": 2.405698299407959,
      "learning_rate": 7.364124351830591e-05,
      "loss": 0.5403,
      "step": 454
    },
    {
      "epoch": 3.64,
      "grad_norm": 3.0911407470703125,
      "learning_rate": 7.352696313021965e-05,
      "loss": 0.7435,
      "step": 455
    },
    {
      "epoch": 3.65,
      "grad_norm": 2.6747987270355225,
      "learning_rate": 7.341252466824572e-05,
      "loss": 0.6372,
      "step": 456
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.501185894012451,
      "learning_rate": 7.329792890127778e-05,
      "loss": 0.6786,
      "step": 457
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.066803216934204,
      "learning_rate": 7.318317659926637e-05,
      "loss": 0.4229,
      "step": 458
    },
    {
      "epoch": 3.67,
      "grad_norm": 2.7606847286224365,
      "learning_rate": 7.30682685332138e-05,
      "loss": 0.6376,
      "step": 459
    },
    {
      "epoch": 3.68,
      "grad_norm": 2.6957833766937256,
      "learning_rate": 7.295320547516893e-05,
      "loss": 0.7154,
      "step": 460
    },
    {
      "epoch": 3.69,
      "grad_norm": 3.0120577812194824,
      "learning_rate": 7.283798819822194e-05,
      "loss": 0.7505,
      "step": 461
    },
    {
      "epoch": 3.7,
      "grad_norm": 3.0676984786987305,
      "learning_rate": 7.272261747649921e-05,
      "loss": 0.8959,
      "step": 462
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.553025007247925,
      "learning_rate": 7.260709408515814e-05,
      "loss": 0.6641,
      "step": 463
    },
    {
      "epoch": 3.71,
      "grad_norm": 2.6834728717803955,
      "learning_rate": 7.24914188003818e-05,
      "loss": 0.7092,
      "step": 464
    },
    {
      "epoch": 3.72,
      "grad_norm": 2.674751043319702,
      "learning_rate": 7.237559239937387e-05,
      "loss": 0.6523,
      "step": 465
    },
    {
      "epoch": 3.73,
      "grad_norm": 2.0744810104370117,
      "learning_rate": 7.225961566035335e-05,
      "loss": 0.5881,
      "step": 466
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.360271453857422,
      "learning_rate": 7.214348936254935e-05,
      "loss": 0.6134,
      "step": 467
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.8815975189208984,
      "learning_rate": 7.202721428619576e-05,
      "loss": 0.6967,
      "step": 468
    },
    {
      "epoch": 3.75,
      "grad_norm": 2.949042558670044,
      "learning_rate": 7.191079121252617e-05,
      "loss": 0.8817,
      "step": 469
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.5045883655548096,
      "learning_rate": 7.179422092376856e-05,
      "loss": 0.6386,
      "step": 470
    },
    {
      "epoch": 3.77,
      "grad_norm": 2.655843496322632,
      "learning_rate": 7.167750420313993e-05,
      "loss": 0.8235,
      "step": 471
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.1979453563690186,
      "learning_rate": 7.156064183484122e-05,
      "loss": 0.6486,
      "step": 472
    },
    {
      "epoch": 3.78,
      "grad_norm": 2.754929780960083,
      "learning_rate": 7.14436346040519e-05,
      "loss": 0.7291,
      "step": 473
    },
    {
      "epoch": 3.79,
      "grad_norm": 1.818258285522461,
      "learning_rate": 7.132648329692478e-05,
      "loss": 0.4945,
      "step": 474
    },
    {
      "epoch": 3.8,
      "grad_norm": 1.9108974933624268,
      "learning_rate": 7.120918870058066e-05,
      "loss": 0.4778,
      "step": 475
    },
    {
      "epoch": 3.81,
      "grad_norm": 2.5595080852508545,
      "learning_rate": 7.109175160310312e-05,
      "loss": 0.8262,
      "step": 476
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.6120128631591797,
      "learning_rate": 7.097417279353316e-05,
      "loss": 0.7821,
      "step": 477
    },
    {
      "epoch": 3.82,
      "grad_norm": 2.3869869709014893,
      "learning_rate": 7.08564530618639e-05,
      "loss": 0.591,
      "step": 478
    },
    {
      "epoch": 3.83,
      "grad_norm": 1.6962873935699463,
      "learning_rate": 7.073859319903536e-05,
      "loss": 0.475,
      "step": 479
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.0443925857543945,
      "learning_rate": 7.062059399692898e-05,
      "loss": 0.5229,
      "step": 480
    },
    {
      "epoch": 3.85,
      "grad_norm": 2.3559257984161377,
      "learning_rate": 7.050245624836249e-05,
      "loss": 0.5617,
      "step": 481
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.754272937774658,
      "learning_rate": 7.038418074708444e-05,
      "loss": 0.7076,
      "step": 482
    },
    {
      "epoch": 3.86,
      "grad_norm": 3.1723568439483643,
      "learning_rate": 7.026576828776895e-05,
      "loss": 0.8241,
      "step": 483
    },
    {
      "epoch": 3.87,
      "grad_norm": 3.195661783218384,
      "learning_rate": 7.01472196660103e-05,
      "loss": 0.7484,
      "step": 484
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.637315273284912,
      "learning_rate": 7.002853567831764e-05,
      "loss": 0.6587,
      "step": 485
    },
    {
      "epoch": 3.89,
      "grad_norm": 2.0859432220458984,
      "learning_rate": 6.990971712210966e-05,
      "loss": 0.471,
      "step": 486
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.4856183528900146,
      "learning_rate": 6.979076479570912e-05,
      "loss": 0.6591,
      "step": 487
    },
    {
      "epoch": 3.9,
      "grad_norm": 1.959283471107483,
      "learning_rate": 6.967167949833763e-05,
      "loss": 0.4599,
      "step": 488
    },
    {
      "epoch": 3.91,
      "grad_norm": 3.113072633743286,
      "learning_rate": 6.955246203011016e-05,
      "loss": 0.8767,
      "step": 489
    },
    {
      "epoch": 3.92,
      "grad_norm": 2.964641571044922,
      "learning_rate": 6.943311319202976e-05,
      "loss": 0.7625,
      "step": 490
    },
    {
      "epoch": 3.93,
      "grad_norm": 2.324512004852295,
      "learning_rate": 6.93136337859821e-05,
      "loss": 0.5663,
      "step": 491
    },
    {
      "epoch": 3.94,
      "grad_norm": 2.6640965938568115,
      "learning_rate": 6.919402461473014e-05,
      "loss": 0.7962,
      "step": 492
    },
    {
      "epoch": 3.94,
      "grad_norm": 2.485121488571167,
      "learning_rate": 6.907428648190864e-05,
      "loss": 0.6288,
      "step": 493
    },
    {
      "epoch": 3.95,
      "grad_norm": 2.774061679840088,
      "learning_rate": 6.895442019201897e-05,
      "loss": 0.7164,
      "step": 494
    },
    {
      "epoch": 3.96,
      "grad_norm": 1.8720459938049316,
      "learning_rate": 6.883442655042344e-05,
      "loss": 0.4547,
      "step": 495
    },
    {
      "epoch": 3.97,
      "grad_norm": 2.4196929931640625,
      "learning_rate": 6.871430636334006e-05,
      "loss": 0.6495,
      "step": 496
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.0436785221099854,
      "learning_rate": 6.859406043783707e-05,
      "loss": 0.4492,
      "step": 497
    },
    {
      "epoch": 3.98,
      "grad_norm": 1.7671951055526733,
      "learning_rate": 6.847368958182759e-05,
      "loss": 0.4718,
      "step": 498
    },
    {
      "epoch": 3.99,
      "grad_norm": 1.9643350839614868,
      "learning_rate": 6.8353194604064e-05,
      "loss": 0.4437,
      "step": 499
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.1782853603363037,
      "learning_rate": 6.823257631413276e-05,
      "loss": 0.8354,
      "step": 500
    },
    {
      "epoch": 4.01,
      "grad_norm": 2.0040183067321777,
      "learning_rate": 6.811183552244878e-05,
      "loss": 0.417,
      "step": 501
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.9077271223068237,
      "learning_rate": 6.799097304025005e-05,
      "loss": 0.3924,
      "step": 502
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.8300385475158691,
      "learning_rate": 6.78699896795922e-05,
      "loss": 0.3791,
      "step": 503
    },
    {
      "epoch": 4.03,
      "grad_norm": 2.269134759902954,
      "learning_rate": 6.774888625334295e-05,
      "loss": 0.5072,
      "step": 504
    },
    {
      "epoch": 4.04,
      "grad_norm": 1.9821033477783203,
      "learning_rate": 6.762766357517683e-05,
      "loss": 0.4657,
      "step": 505
    },
    {
      "epoch": 4.05,
      "grad_norm": 2.608799934387207,
      "learning_rate": 6.750632245956953e-05,
      "loss": 0.5914,
      "step": 506
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.677276849746704,
      "learning_rate": 6.738486372179254e-05,
      "loss": 0.3648,
      "step": 507
    },
    {
      "epoch": 4.06,
      "grad_norm": 2.0655417442321777,
      "learning_rate": 6.72632881779076e-05,
      "loss": 0.5218,
      "step": 508
    },
    {
      "epoch": 4.07,
      "grad_norm": 1.8502097129821777,
      "learning_rate": 6.714159664476127e-05,
      "loss": 0.4034,
      "step": 509
    },
    {
      "epoch": 4.08,
      "grad_norm": 2.5591323375701904,
      "learning_rate": 6.701978993997941e-05,
      "loss": 0.4767,
      "step": 510
    },
    {
      "epoch": 4.09,
      "grad_norm": 1.380989670753479,
      "learning_rate": 6.689786888196175e-05,
      "loss": 0.3339,
      "step": 511
    },
    {
      "epoch": 4.1,
      "grad_norm": 2.0335421562194824,
      "learning_rate": 6.677583428987625e-05,
      "loss": 0.418,
      "step": 512
    },
    {
      "epoch": 4.1,
      "grad_norm": 2.2989821434020996,
      "learning_rate": 6.66536869836538e-05,
      "loss": 0.491,
      "step": 513
    },
    {
      "epoch": 4.11,
      "grad_norm": 1.7789101600646973,
      "learning_rate": 6.653142778398248e-05,
      "loss": 0.3639,
      "step": 514
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.8311123847961426,
      "learning_rate": 6.640905751230225e-05,
      "loss": 0.3632,
      "step": 515
    },
    {
      "epoch": 4.13,
      "grad_norm": 2.039252758026123,
      "learning_rate": 6.628657699079932e-05,
      "loss": 0.4343,
      "step": 516
    },
    {
      "epoch": 4.14,
      "grad_norm": 1.5188508033752441,
      "learning_rate": 6.616398704240064e-05,
      "loss": 0.3228,
      "step": 517
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.0917367935180664,
      "learning_rate": 6.604128849076838e-05,
      "loss": 0.4122,
      "step": 518
    },
    {
      "epoch": 4.15,
      "grad_norm": 2.660696029663086,
      "learning_rate": 6.591848216029444e-05,
      "loss": 0.5526,
      "step": 519
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.0655689239501953,
      "learning_rate": 6.579556887609482e-05,
      "loss": 0.4127,
      "step": 520
    },
    {
      "epoch": 4.17,
      "grad_norm": 2.2924273014068604,
      "learning_rate": 6.567254946400411e-05,
      "loss": 0.4538,
      "step": 521
    },
    {
      "epoch": 4.18,
      "grad_norm": 1.9917638301849365,
      "learning_rate": 6.554942475057004e-05,
      "loss": 0.4187,
      "step": 522
    },
    {
      "epoch": 4.18,
      "grad_norm": 2.4491302967071533,
      "learning_rate": 6.542619556304774e-05,
      "loss": 0.4529,
      "step": 523
    },
    {
      "epoch": 4.19,
      "grad_norm": 1.6949936151504517,
      "learning_rate": 6.530286272939437e-05,
      "loss": 0.3511,
      "step": 524
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.278505802154541,
      "learning_rate": 6.517942707826343e-05,
      "loss": 0.4797,
      "step": 525
    },
    {
      "epoch": 4.21,
      "grad_norm": 1.6250948905944824,
      "learning_rate": 6.505588943899922e-05,
      "loss": 0.349,
      "step": 526
    },
    {
      "epoch": 4.22,
      "grad_norm": 2.217249631881714,
      "learning_rate": 6.493225064163133e-05,
      "loss": 0.4095,
      "step": 527
    },
    {
      "epoch": 4.22,
      "grad_norm": 1.4347848892211914,
      "learning_rate": 6.480851151686898e-05,
      "loss": 0.287,
      "step": 528
    },
    {
      "epoch": 4.23,
      "grad_norm": 2.0317091941833496,
      "learning_rate": 6.468467289609547e-05,
      "loss": 0.4286,
      "step": 529
    },
    {
      "epoch": 4.24,
      "grad_norm": 2.455547571182251,
      "learning_rate": 6.456073561136261e-05,
      "loss": 0.4694,
      "step": 530
    },
    {
      "epoch": 4.25,
      "grad_norm": 1.631833553314209,
      "learning_rate": 6.443670049538512e-05,
      "loss": 0.3476,
      "step": 531
    },
    {
      "epoch": 4.26,
      "grad_norm": 2.0641183853149414,
      "learning_rate": 6.431256838153504e-05,
      "loss": 0.402,
      "step": 532
    },
    {
      "epoch": 4.26,
      "grad_norm": 2.241576910018921,
      "learning_rate": 6.41883401038361e-05,
      "loss": 0.4652,
      "step": 533
    },
    {
      "epoch": 4.27,
      "grad_norm": 1.6486846208572388,
      "learning_rate": 6.406401649695814e-05,
      "loss": 0.3375,
      "step": 534
    },
    {
      "epoch": 4.28,
      "grad_norm": 1.7016408443450928,
      "learning_rate": 6.393959839621153e-05,
      "loss": 0.3154,
      "step": 535
    },
    {
      "epoch": 4.29,
      "grad_norm": 2.165884017944336,
      "learning_rate": 6.381508663754153e-05,
      "loss": 0.4432,
      "step": 536
    },
    {
      "epoch": 4.3,
      "grad_norm": 1.9559366703033447,
      "learning_rate": 6.369048205752261e-05,
      "loss": 0.3747,
      "step": 537
    },
    {
      "epoch": 4.3,
      "grad_norm": 2.073488473892212,
      "learning_rate": 6.356578549335294e-05,
      "loss": 0.3965,
      "step": 538
    },
    {
      "epoch": 4.31,
      "grad_norm": 1.5522257089614868,
      "learning_rate": 6.344099778284876e-05,
      "loss": 0.3468,
      "step": 539
    },
    {
      "epoch": 4.32,
      "grad_norm": 2.2791907787323,
      "learning_rate": 6.331611976443862e-05,
      "loss": 0.4651,
      "step": 540
    },
    {
      "epoch": 4.33,
      "grad_norm": 2.4559383392333984,
      "learning_rate": 6.31911522771579e-05,
      "loss": 0.4968,
      "step": 541
    },
    {
      "epoch": 4.34,
      "grad_norm": 2.2088232040405273,
      "learning_rate": 6.306609616064304e-05,
      "loss": 0.5063,
      "step": 542
    },
    {
      "epoch": 4.34,
      "grad_norm": 1.5664844512939453,
      "learning_rate": 6.294095225512603e-05,
      "loss": 0.2862,
      "step": 543
    },
    {
      "epoch": 4.35,
      "grad_norm": 1.9506347179412842,
      "learning_rate": 6.281572140142871e-05,
      "loss": 0.4013,
      "step": 544
    },
    {
      "epoch": 4.36,
      "grad_norm": 2.1070408821105957,
      "learning_rate": 6.269040444095704e-05,
      "loss": 0.3863,
      "step": 545
    },
    {
      "epoch": 4.37,
      "grad_norm": 2.0632028579711914,
      "learning_rate": 6.256500221569556e-05,
      "loss": 0.4527,
      "step": 546
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.023446559906006,
      "learning_rate": 6.243951556820169e-05,
      "loss": 0.4046,
      "step": 547
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.443181037902832,
      "learning_rate": 6.231394534160008e-05,
      "loss": 0.5705,
      "step": 548
    },
    {
      "epoch": 4.39,
      "grad_norm": 1.8140839338302612,
      "learning_rate": 6.218829237957688e-05,
      "loss": 0.3409,
      "step": 549
    },
    {
      "epoch": 4.4,
      "grad_norm": 2.195836305618286,
      "learning_rate": 6.206255752637422e-05,
      "loss": 0.421,
      "step": 550
    },
    {
      "epoch": 4.41,
      "grad_norm": 2.1525039672851562,
      "learning_rate": 6.193674162678437e-05,
      "loss": 0.5001,
      "step": 551
    },
    {
      "epoch": 4.42,
      "grad_norm": 1.7491719722747803,
      "learning_rate": 6.181084552614413e-05,
      "loss": 0.3584,
      "step": 552
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.4488725662231445,
      "learning_rate": 6.168487007032922e-05,
      "loss": 0.5154,
      "step": 553
    },
    {
      "epoch": 4.43,
      "grad_norm": 1.7275681495666504,
      "learning_rate": 6.15588161057485e-05,
      "loss": 0.3938,
      "step": 554
    },
    {
      "epoch": 4.44,
      "grad_norm": 1.8828773498535156,
      "learning_rate": 6.143268447933827e-05,
      "loss": 0.4159,
      "step": 555
    },
    {
      "epoch": 4.45,
      "grad_norm": 2.27419114112854,
      "learning_rate": 6.130647603855673e-05,
      "loss": 0.4876,
      "step": 556
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.47548246383667,
      "learning_rate": 6.118019163137813e-05,
      "loss": 0.5473,
      "step": 557
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.39029598236084,
      "learning_rate": 6.10538321062871e-05,
      "loss": 0.4707,
      "step": 558
    },
    {
      "epoch": 4.47,
      "grad_norm": 1.5731579065322876,
      "learning_rate": 6.092739831227298e-05,
      "loss": 0.3329,
      "step": 559
    },
    {
      "epoch": 4.48,
      "grad_norm": 1.874039649963379,
      "learning_rate": 6.0800891098824186e-05,
      "loss": 0.3679,
      "step": 560
    },
    {
      "epoch": 4.49,
      "grad_norm": 2.1965136528015137,
      "learning_rate": 6.067431131592234e-05,
      "loss": 0.4731,
      "step": 561
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.003187894821167,
      "learning_rate": 6.054765981403666e-05,
      "loss": 0.4086,
      "step": 562
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.078892707824707,
      "learning_rate": 6.0420937444118284e-05,
      "loss": 0.3408,
      "step": 563
    },
    {
      "epoch": 4.51,
      "grad_norm": 1.9963995218276978,
      "learning_rate": 6.029414505759448e-05,
      "loss": 0.3756,
      "step": 564
    },
    {
      "epoch": 4.52,
      "grad_norm": 2.451946496963501,
      "learning_rate": 6.016728350636288e-05,
      "loss": 0.5468,
      "step": 565
    },
    {
      "epoch": 4.53,
      "grad_norm": 1.9934735298156738,
      "learning_rate": 6.004035364278593e-05,
      "loss": 0.3994,
      "step": 566
    },
    {
      "epoch": 4.54,
      "grad_norm": 1.647086262702942,
      "learning_rate": 5.9913356319684974e-05,
      "loss": 0.3565,
      "step": 567
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.285101890563965,
      "learning_rate": 5.9786292390334654e-05,
      "loss": 0.5042,
      "step": 568
    },
    {
      "epoch": 4.55,
      "grad_norm": 2.2821879386901855,
      "learning_rate": 5.965916270845709e-05,
      "loss": 0.4276,
      "step": 569
    },
    {
      "epoch": 4.56,
      "grad_norm": 1.7744947671890259,
      "learning_rate": 5.953196812821622e-05,
      "loss": 0.4371,
      "step": 570
    },
    {
      "epoch": 4.57,
      "grad_norm": 1.569554090499878,
      "learning_rate": 5.940470950421198e-05,
      "loss": 0.3659,
      "step": 571
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.012939453125,
      "learning_rate": 5.9277387691474676e-05,
      "loss": 0.4156,
      "step": 572
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.5619277954101562,
      "learning_rate": 5.915000354545907e-05,
      "loss": 0.5542,
      "step": 573
    },
    {
      "epoch": 4.59,
      "grad_norm": 1.5185028314590454,
      "learning_rate": 5.9022557922038815e-05,
      "loss": 0.3074,
      "step": 574
    },
    {
      "epoch": 4.6,
      "grad_norm": 1.8631948232650757,
      "learning_rate": 5.88950516775006e-05,
      "loss": 0.386,
      "step": 575
    },
    {
      "epoch": 4.61,
      "grad_norm": 2.0171260833740234,
      "learning_rate": 5.8767485668538394e-05,
      "loss": 0.4599,
      "step": 576
    },
    {
      "epoch": 4.62,
      "grad_norm": 1.673337697982788,
      "learning_rate": 5.863986075224772e-05,
      "loss": 0.3753,
      "step": 577
    },
    {
      "epoch": 4.62,
      "grad_norm": 2.827918529510498,
      "learning_rate": 5.851217778611994e-05,
      "loss": 0.571,
      "step": 578
    },
    {
      "epoch": 4.63,
      "grad_norm": 2.1985204219818115,
      "learning_rate": 5.838443762803636e-05,
      "loss": 0.5111,
      "step": 579
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.1026480197906494,
      "learning_rate": 5.825664113626258e-05,
      "loss": 0.501,
      "step": 580
    },
    {
      "epoch": 4.65,
      "grad_norm": 2.20857310295105,
      "learning_rate": 5.8128789169442756e-05,
      "loss": 0.4431,
      "step": 581
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.245363235473633,
      "learning_rate": 5.800088258659371e-05,
      "loss": 0.4735,
      "step": 582
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.1408390998840332,
      "learning_rate": 5.78729222470992e-05,
      "loss": 0.2795,
      "step": 583
    },
    {
      "epoch": 4.67,
      "grad_norm": 1.7877124547958374,
      "learning_rate": 5.774490901070424e-05,
      "loss": 0.3828,
      "step": 584
    },
    {
      "epoch": 4.68,
      "grad_norm": 1.6089047193527222,
      "learning_rate": 5.761684373750919e-05,
      "loss": 0.3746,
      "step": 585
    },
    {
      "epoch": 4.69,
      "grad_norm": 1.8911703824996948,
      "learning_rate": 5.748872728796408e-05,
      "loss": 0.3989,
      "step": 586
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.421603798866272,
      "learning_rate": 5.736056052286274e-05,
      "loss": 0.3689,
      "step": 587
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.354543924331665,
      "learning_rate": 5.7232344303337106e-05,
      "loss": 0.3606,
      "step": 588
    },
    {
      "epoch": 4.71,
      "grad_norm": 2.3460726737976074,
      "learning_rate": 5.710407949085135e-05,
      "loss": 0.4428,
      "step": 589
    },
    {
      "epoch": 4.72,
      "grad_norm": 1.9283829927444458,
      "learning_rate": 5.697576694719616e-05,
      "loss": 0.4789,
      "step": 590
    },
    {
      "epoch": 4.73,
      "grad_norm": 1.9359506368637085,
      "learning_rate": 5.684740753448291e-05,
      "loss": 0.4191,
      "step": 591
    },
    {
      "epoch": 4.74,
      "grad_norm": 1.7955666780471802,
      "learning_rate": 5.671900211513791e-05,
      "loss": 0.3973,
      "step": 592
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.098757743835449,
      "learning_rate": 5.6590551551896506e-05,
      "loss": 0.45,
      "step": 593
    },
    {
      "epoch": 4.75,
      "grad_norm": 1.9369157552719116,
      "learning_rate": 5.646205670779745e-05,
      "loss": 0.4231,
      "step": 594
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.956931710243225,
      "learning_rate": 5.633351844617697e-05,
      "loss": 0.4302,
      "step": 595
    },
    {
      "epoch": 4.77,
      "grad_norm": 1.622622013092041,
      "learning_rate": 5.620493763066297e-05,
      "loss": 0.3294,
      "step": 596
    },
    {
      "epoch": 4.78,
      "grad_norm": 2.276327610015869,
      "learning_rate": 5.607631512516934e-05,
      "loss": 0.4851,
      "step": 597
    },
    {
      "epoch": 4.78,
      "grad_norm": 2.18644642829895,
      "learning_rate": 5.5947651793890025e-05,
      "loss": 0.4346,
      "step": 598
    },
    {
      "epoch": 4.79,
      "grad_norm": 1.6551727056503296,
      "learning_rate": 5.5818948501293275e-05,
      "loss": 0.3632,
      "step": 599
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.3923618793487549,
      "learning_rate": 5.5690206112115884e-05,
      "loss": 0.3348,
      "step": 600
    },
    {
      "epoch": 4.81,
      "grad_norm": 2.6822428703308105,
      "learning_rate": 5.5561425491357255e-05,
      "loss": 0.5993,
      "step": 601
    },
    {
      "epoch": 4.82,
      "grad_norm": 1.826715350151062,
      "learning_rate": 5.543260750427373e-05,
      "loss": 0.4233,
      "step": 602
    },
    {
      "epoch": 4.82,
      "grad_norm": 1.788386344909668,
      "learning_rate": 5.5303753016372675e-05,
      "loss": 0.3765,
      "step": 603
    },
    {
      "epoch": 4.83,
      "grad_norm": 2.5032002925872803,
      "learning_rate": 5.517486289340669e-05,
      "loss": 0.5071,
      "step": 604
    },
    {
      "epoch": 4.84,
      "grad_norm": 2.334075927734375,
      "learning_rate": 5.504593800136783e-05,
      "loss": 0.4675,
      "step": 605
    },
    {
      "epoch": 4.85,
      "grad_norm": 1.8744237422943115,
      "learning_rate": 5.491697920648174e-05,
      "loss": 0.3768,
      "step": 606
    },
    {
      "epoch": 4.86,
      "grad_norm": 2.9240870475769043,
      "learning_rate": 5.4787987375201866e-05,
      "loss": 0.6744,
      "step": 607
    },
    {
      "epoch": 4.86,
      "grad_norm": 2.123464584350586,
      "learning_rate": 5.465896337420359e-05,
      "loss": 0.4734,
      "step": 608
    },
    {
      "epoch": 4.87,
      "grad_norm": 1.481386661529541,
      "learning_rate": 5.4529908070378466e-05,
      "loss": 0.3593,
      "step": 609
    },
    {
      "epoch": 4.88,
      "grad_norm": 2.072312355041504,
      "learning_rate": 5.440082233082837e-05,
      "loss": 0.4146,
      "step": 610
    },
    {
      "epoch": 4.89,
      "grad_norm": 1.9813525676727295,
      "learning_rate": 5.427170702285964e-05,
      "loss": 0.4243,
      "step": 611
    },
    {
      "epoch": 4.9,
      "grad_norm": 1.7901928424835205,
      "learning_rate": 5.414256301397731e-05,
      "loss": 0.3684,
      "step": 612
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.473245620727539,
      "learning_rate": 5.401339117187926e-05,
      "loss": 0.5496,
      "step": 613
    },
    {
      "epoch": 4.91,
      "grad_norm": 1.3343653678894043,
      "learning_rate": 5.3884192364450325e-05,
      "loss": 0.2515,
      "step": 614
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.4004786014556885,
      "learning_rate": 5.375496745975655e-05,
      "loss": 0.5217,
      "step": 615
    },
    {
      "epoch": 4.93,
      "grad_norm": 2.0880024433135986,
      "learning_rate": 5.3625717326039336e-05,
      "loss": 0.4719,
      "step": 616
    },
    {
      "epoch": 4.94,
      "grad_norm": 1.5732364654541016,
      "learning_rate": 5.349644283170957e-05,
      "loss": 0.3361,
      "step": 617
    },
    {
      "epoch": 4.94,
      "grad_norm": 2.364489793777466,
      "learning_rate": 5.336714484534182e-05,
      "loss": 0.4484,
      "step": 618
    },
    {
      "epoch": 4.95,
      "grad_norm": 1.7944588661193848,
      "learning_rate": 5.32378242356685e-05,
      "loss": 0.3794,
      "step": 619
    },
    {
      "epoch": 4.96,
      "grad_norm": 2.1843409538269043,
      "learning_rate": 5.3108481871574036e-05,
      "loss": 0.4823,
      "step": 620
    },
    {
      "epoch": 4.97,
      "grad_norm": 2.1563515663146973,
      "learning_rate": 5.2979118622088974e-05,
      "loss": 0.5617,
      "step": 621
    },
    {
      "epoch": 4.98,
      "grad_norm": 2.5593717098236084,
      "learning_rate": 5.284973535638423e-05,
      "loss": 0.4839,
      "step": 622
    },
    {
      "epoch": 4.98,
      "grad_norm": 2.1337053775787354,
      "learning_rate": 5.272033294376522e-05,
      "loss": 0.4681,
      "step": 623
    },
    {
      "epoch": 4.99,
      "grad_norm": 2.607548713684082,
      "learning_rate": 5.259091225366593e-05,
      "loss": 0.572,
      "step": 624
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.2913742065429688,
      "learning_rate": 5.246147415564321e-05,
      "loss": 0.5042,
      "step": 625
    },
    {
      "epoch": 5.01,
      "grad_norm": 1.9553354978561401,
      "learning_rate": 5.233201951937088e-05,
      "loss": 0.3706,
      "step": 626
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.131145715713501,
      "learning_rate": 5.2202549214633833e-05,
      "loss": 0.2915,
      "step": 627
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.9684871435165405,
      "learning_rate": 5.207306411132228e-05,
      "loss": 0.3503,
      "step": 628
    },
    {
      "epoch": 5.03,
      "grad_norm": 1.5417519807815552,
      "learning_rate": 5.1943565079425805e-05,
      "loss": 0.2825,
      "step": 629
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.7333829402923584,
      "learning_rate": 5.181405298902763e-05,
      "loss": 0.3657,
      "step": 630
    },
    {
      "epoch": 5.05,
      "grad_norm": 1.4527215957641602,
      "learning_rate": 5.168452871029871e-05,
      "loss": 0.2687,
      "step": 631
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.6347635984420776,
      "learning_rate": 5.155499311349185e-05,
      "loss": 0.3265,
      "step": 632
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.5014501810073853,
      "learning_rate": 5.142544706893595e-05,
      "loss": 0.321,
      "step": 633
    },
    {
      "epoch": 5.07,
      "grad_norm": 1.5177185535430908,
      "learning_rate": 5.1295891447030054e-05,
      "loss": 0.2864,
      "step": 634
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.7527066469192505,
      "learning_rate": 5.116632711823761e-05,
      "loss": 0.3035,
      "step": 635
    },
    {
      "epoch": 5.09,
      "grad_norm": 2.166757345199585,
      "learning_rate": 5.103675495308054e-05,
      "loss": 0.401,
      "step": 636
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.8076763153076172,
      "learning_rate": 5.090717582213338e-05,
      "loss": 0.3437,
      "step": 637
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.748561978340149,
      "learning_rate": 5.077759059601755e-05,
      "loss": 0.3489,
      "step": 638
    },
    {
      "epoch": 5.11,
      "grad_norm": 1.780428171157837,
      "learning_rate": 5.064800014539536e-05,
      "loss": 0.3005,
      "step": 639
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.9052661657333374,
      "learning_rate": 5.0518405340964223e-05,
      "loss": 0.3124,
      "step": 640
    },
    {
      "epoch": 5.13,
      "grad_norm": 1.226081132888794,
      "learning_rate": 5.038880705345086e-05,
      "loss": 0.2573,
      "step": 641
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.7221766710281372,
      "learning_rate": 5.025920615360532e-05,
      "loss": 0.3407,
      "step": 642
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.3834518194198608,
      "learning_rate": 5.012960351219526e-05,
      "loss": 0.232,
      "step": 643
    },
    {
      "epoch": 5.15,
      "grad_norm": 1.4152488708496094,
      "learning_rate": 5e-05,
      "loss": 0.2864,
      "step": 644
    },
    {
      "epoch": 5.16,
      "grad_norm": 2.002601385116577,
      "learning_rate": 4.987039648780475e-05,
      "loss": 0.352,
      "step": 645
    },
    {
      "epoch": 5.17,
      "grad_norm": 1.5097951889038086,
      "learning_rate": 4.9740793846394695e-05,
      "loss": 0.2576,
      "step": 646
    },
    {
      "epoch": 5.18,
      "grad_norm": 1.7249195575714111,
      "learning_rate": 4.961119294654915e-05,
      "loss": 0.3548,
      "step": 647
    },
    {
      "epoch": 5.18,
      "grad_norm": 1.8555879592895508,
      "learning_rate": 4.9481594659035775e-05,
      "loss": 0.3207,
      "step": 648
    },
    {
      "epoch": 5.19,
      "grad_norm": 1.2356165647506714,
      "learning_rate": 4.935199985460466e-05,
      "loss": 0.2357,
      "step": 649
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.7938127517700195,
      "learning_rate": 4.9222409403982453e-05,
      "loss": 0.2803,
      "step": 650
    },
    {
      "epoch": 5.21,
      "grad_norm": 1.3356934785842896,
      "learning_rate": 4.9092824177866617e-05,
      "loss": 0.2643,
      "step": 651
    },
    {
      "epoch": 5.22,
      "grad_norm": 1.5118645429611206,
      "learning_rate": 4.8963245046919495e-05,
      "loss": 0.3014,
      "step": 652
    },
    {
      "epoch": 5.22,
      "grad_norm": 1.4875315427780151,
      "learning_rate": 4.883367288176239e-05,
      "loss": 0.3193,
      "step": 653
    },
    {
      "epoch": 5.23,
      "grad_norm": 1.2096186876296997,
      "learning_rate": 4.8704108552969944e-05,
      "loss": 0.2805,
      "step": 654
    },
    {
      "epoch": 5.24,
      "grad_norm": 1.1809335947036743,
      "learning_rate": 4.857455293106408e-05,
      "loss": 0.2372,
      "step": 655
    },
    {
      "epoch": 5.25,
      "grad_norm": 1.495741367340088,
      "learning_rate": 4.844500688650816e-05,
      "loss": 0.3133,
      "step": 656
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.8989402055740356,
      "learning_rate": 4.831547128970129e-05,
      "loss": 0.3181,
      "step": 657
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.4166022539138794,
      "learning_rate": 4.818594701097238e-05,
      "loss": 0.2844,
      "step": 658
    },
    {
      "epoch": 5.27,
      "grad_norm": 1.6444371938705444,
      "learning_rate": 4.805643492057421e-05,
      "loss": 0.3107,
      "step": 659
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.6698633432388306,
      "learning_rate": 4.7926935888677735e-05,
      "loss": 0.3653,
      "step": 660
    },
    {
      "epoch": 5.29,
      "grad_norm": 1.5046340227127075,
      "learning_rate": 4.779745078536618e-05,
      "loss": 0.3152,
      "step": 661
    },
    {
      "epoch": 5.3,
      "grad_norm": 1.0906387567520142,
      "learning_rate": 4.7667980480629124e-05,
      "loss": 0.2305,
      "step": 662
    },
    {
      "epoch": 5.3,
      "grad_norm": 1.4116519689559937,
      "learning_rate": 4.753852584435679e-05,
      "loss": 0.2556,
      "step": 663
    },
    {
      "epoch": 5.31,
      "grad_norm": 1.3319398164749146,
      "learning_rate": 4.740908774633408e-05,
      "loss": 0.2976,
      "step": 664
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.3366268873214722,
      "learning_rate": 4.727966705623479e-05,
      "loss": 0.2956,
      "step": 665
    },
    {
      "epoch": 5.33,
      "grad_norm": 1.4600882530212402,
      "learning_rate": 4.7150264643615765e-05,
      "loss": 0.2956,
      "step": 666
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.1044676303863525,
      "learning_rate": 4.702088137791104e-05,
      "loss": 0.3513,
      "step": 667
    },
    {
      "epoch": 5.34,
      "grad_norm": 1.432354211807251,
      "learning_rate": 4.6891518128425976e-05,
      "loss": 0.2371,
      "step": 668
    },
    {
      "epoch": 5.35,
      "grad_norm": 1.4924442768096924,
      "learning_rate": 4.676217576433149e-05,
      "loss": 0.2773,
      "step": 669
    },
    {
      "epoch": 5.36,
      "grad_norm": 1.1607275009155273,
      "learning_rate": 4.663285515465818e-05,
      "loss": 0.2142,
      "step": 670
    },
    {
      "epoch": 5.37,
      "grad_norm": 1.4512284994125366,
      "learning_rate": 4.650355716829043e-05,
      "loss": 0.2701,
      "step": 671
    },
    {
      "epoch": 5.38,
      "grad_norm": 1.399477481842041,
      "learning_rate": 4.637428267396069e-05,
      "loss": 0.2796,
      "step": 672
    },
    {
      "epoch": 5.38,
      "grad_norm": 1.510169267654419,
      "learning_rate": 4.624503254024347e-05,
      "loss": 0.2655,
      "step": 673
    },
    {
      "epoch": 5.39,
      "grad_norm": 1.5021685361862183,
      "learning_rate": 4.611580763554969e-05,
      "loss": 0.3018,
      "step": 674
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.3884810209274292,
      "learning_rate": 4.598660882812076e-05,
      "loss": 0.2839,
      "step": 675
    },
    {
      "epoch": 5.41,
      "grad_norm": 1.2434605360031128,
      "learning_rate": 4.5857436986022696e-05,
      "loss": 0.2247,
      "step": 676
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.6074227094650269,
      "learning_rate": 4.572829297714037e-05,
      "loss": 0.3106,
      "step": 677
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.544811725616455,
      "learning_rate": 4.5599177669171654e-05,
      "loss": 0.2902,
      "step": 678
    },
    {
      "epoch": 5.43,
      "grad_norm": 1.5548033714294434,
      "learning_rate": 4.547009192962155e-05,
      "loss": 0.3037,
      "step": 679
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.4862385988235474,
      "learning_rate": 4.534103662579642e-05,
      "loss": 0.3078,
      "step": 680
    },
    {
      "epoch": 5.45,
      "grad_norm": 1.3278529644012451,
      "learning_rate": 4.521201262479815e-05,
      "loss": 0.2402,
      "step": 681
    },
    {
      "epoch": 5.46,
      "grad_norm": 1.8244988918304443,
      "learning_rate": 4.508302079351827e-05,
      "loss": 0.3261,
      "step": 682
    },
    {
      "epoch": 5.46,
      "grad_norm": 1.5452960729599,
      "learning_rate": 4.495406199863218e-05,
      "loss": 0.3135,
      "step": 683
    },
    {
      "epoch": 5.47,
      "grad_norm": 2.121493339538574,
      "learning_rate": 4.482513710659332e-05,
      "loss": 0.3336,
      "step": 684
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.6056749820709229,
      "learning_rate": 4.469624698362734e-05,
      "loss": 0.3219,
      "step": 685
    },
    {
      "epoch": 5.49,
      "grad_norm": 1.9254132509231567,
      "learning_rate": 4.456739249572627e-05,
      "loss": 0.3247,
      "step": 686
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.1054143905639648,
      "learning_rate": 4.443857450864276e-05,
      "loss": 0.2453,
      "step": 687
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.5800836086273193,
      "learning_rate": 4.4309793887884135e-05,
      "loss": 0.3102,
      "step": 688
    },
    {
      "epoch": 5.51,
      "grad_norm": 2.338331699371338,
      "learning_rate": 4.418105149870673e-05,
      "loss": 0.3865,
      "step": 689
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.6556905508041382,
      "learning_rate": 4.405234820611001e-05,
      "loss": 0.3,
      "step": 690
    },
    {
      "epoch": 5.53,
      "grad_norm": 1.5681066513061523,
      "learning_rate": 4.3923684874830675e-05,
      "loss": 0.2673,
      "step": 691
    },
    {
      "epoch": 5.54,
      "grad_norm": 1.653914451599121,
      "learning_rate": 4.3795062369337034e-05,
      "loss": 0.3511,
      "step": 692
    },
    {
      "epoch": 5.54,
      "grad_norm": 2.0314810276031494,
      "learning_rate": 4.3666481553823054e-05,
      "loss": 0.3803,
      "step": 693
    },
    {
      "epoch": 5.55,
      "grad_norm": 1.687314510345459,
      "learning_rate": 4.3537943292202555e-05,
      "loss": 0.3157,
      "step": 694
    },
    {
      "epoch": 5.56,
      "grad_norm": 2.1898081302642822,
      "learning_rate": 4.34094484481035e-05,
      "loss": 0.3935,
      "step": 695
    },
    {
      "epoch": 5.57,
      "grad_norm": 1.7666113376617432,
      "learning_rate": 4.3280997884862116e-05,
      "loss": 0.3317,
      "step": 696
    },
    {
      "epoch": 5.58,
      "grad_norm": 2.2341063022613525,
      "learning_rate": 4.31525924655171e-05,
      "loss": 0.3613,
      "step": 697
    },
    {
      "epoch": 5.58,
      "grad_norm": 1.4673924446105957,
      "learning_rate": 4.3024233052803855e-05,
      "loss": 0.3101,
      "step": 698
    },
    {
      "epoch": 5.59,
      "grad_norm": 1.984660267829895,
      "learning_rate": 4.289592050914867e-05,
      "loss": 0.3289,
      "step": 699
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.6214131116867065,
      "learning_rate": 4.276765569666291e-05,
      "loss": 0.2907,
      "step": 700
    },
    {
      "epoch": 5.61,
      "grad_norm": 1.6733195781707764,
      "learning_rate": 4.263943947713727e-05,
      "loss": 0.2972,
      "step": 701
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.224055767059326,
      "learning_rate": 4.251127271203593e-05,
      "loss": 0.3597,
      "step": 702
    },
    {
      "epoch": 5.62,
      "grad_norm": 1.7954000234603882,
      "learning_rate": 4.238315626249081e-05,
      "loss": 0.313,
      "step": 703
    },
    {
      "epoch": 5.63,
      "grad_norm": 1.8326102495193481,
      "learning_rate": 4.2255090989295764e-05,
      "loss": 0.2952,
      "step": 704
    },
    {
      "epoch": 5.64,
      "grad_norm": 1.8507905006408691,
      "learning_rate": 4.212707775290081e-05,
      "loss": 0.3157,
      "step": 705
    },
    {
      "epoch": 5.65,
      "grad_norm": 1.5627151727676392,
      "learning_rate": 4.199911741340631e-05,
      "loss": 0.2579,
      "step": 706
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.9028730392456055,
      "learning_rate": 4.187121083055724e-05,
      "loss": 0.3065,
      "step": 707
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.6399967670440674,
      "learning_rate": 4.1743358863737436e-05,
      "loss": 0.3376,
      "step": 708
    },
    {
      "epoch": 5.67,
      "grad_norm": 1.6231045722961426,
      "learning_rate": 4.1615562371963654e-05,
      "loss": 0.2892,
      "step": 709
    },
    {
      "epoch": 5.68,
      "grad_norm": 1.5802385807037354,
      "learning_rate": 4.148782221388007e-05,
      "loss": 0.3045,
      "step": 710
    },
    {
      "epoch": 5.69,
      "grad_norm": 1.8000767230987549,
      "learning_rate": 4.136013924775228e-05,
      "loss": 0.3256,
      "step": 711
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.3165303468704224,
      "learning_rate": 4.123251433146162e-05,
      "loss": 0.2716,
      "step": 712
    },
    {
      "epoch": 5.7,
      "grad_norm": 2.145362377166748,
      "learning_rate": 4.110494832249939e-05,
      "loss": 0.33,
      "step": 713
    },
    {
      "epoch": 5.71,
      "grad_norm": 1.1892988681793213,
      "learning_rate": 4.097744207796119e-05,
      "loss": 0.2257,
      "step": 714
    },
    {
      "epoch": 5.72,
      "grad_norm": 2.3473145961761475,
      "learning_rate": 4.084999645454094e-05,
      "loss": 0.3347,
      "step": 715
    },
    {
      "epoch": 5.73,
      "grad_norm": 2.257202625274658,
      "learning_rate": 4.0722612308525335e-05,
      "loss": 0.3834,
      "step": 716
    },
    {
      "epoch": 5.74,
      "grad_norm": 1.4653561115264893,
      "learning_rate": 4.059529049578802e-05,
      "loss": 0.3115,
      "step": 717
    },
    {
      "epoch": 5.74,
      "grad_norm": 1.1059671640396118,
      "learning_rate": 4.0468031871783796e-05,
      "loss": 0.2055,
      "step": 718
    },
    {
      "epoch": 5.75,
      "grad_norm": 1.282146692276001,
      "learning_rate": 4.034083729154291e-05,
      "loss": 0.2784,
      "step": 719
    },
    {
      "epoch": 5.76,
      "grad_norm": 1.7585482597351074,
      "learning_rate": 4.021370760966536e-05,
      "loss": 0.298,
      "step": 720
    },
    {
      "epoch": 5.77,
      "grad_norm": 1.4262876510620117,
      "learning_rate": 4.008664368031503e-05,
      "loss": 0.2767,
      "step": 721
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.1905674934387207,
      "learning_rate": 3.9959646357214084e-05,
      "loss": 0.2278,
      "step": 722
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.8155499696731567,
      "learning_rate": 3.9832716493637127e-05,
      "loss": 0.285,
      "step": 723
    },
    {
      "epoch": 5.79,
      "grad_norm": 2.181691884994507,
      "learning_rate": 3.970585494240554e-05,
      "loss": 0.3466,
      "step": 724
    },
    {
      "epoch": 5.8,
      "grad_norm": 2.0954856872558594,
      "learning_rate": 3.9579062555881734e-05,
      "loss": 0.3158,
      "step": 725
    },
    {
      "epoch": 5.81,
      "grad_norm": 1.8084510564804077,
      "learning_rate": 3.945234018596335e-05,
      "loss": 0.2856,
      "step": 726
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.8631155490875244,
      "learning_rate": 3.9325688684077675e-05,
      "loss": 0.3055,
      "step": 727
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.5933723449707031,
      "learning_rate": 3.919910890117584e-05,
      "loss": 0.2371,
      "step": 728
    },
    {
      "epoch": 5.83,
      "grad_norm": 1.5472594499588013,
      "learning_rate": 3.907260168772703e-05,
      "loss": 0.2983,
      "step": 729
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.058926582336426,
      "learning_rate": 3.894616789371291e-05,
      "loss": 0.3645,
      "step": 730
    },
    {
      "epoch": 5.85,
      "grad_norm": 1.548988938331604,
      "learning_rate": 3.8819808368621894e-05,
      "loss": 0.3152,
      "step": 731
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.7200944423675537,
      "learning_rate": 3.8693523961443274e-05,
      "loss": 0.2938,
      "step": 732
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.6465846300125122,
      "learning_rate": 3.856731552066173e-05,
      "loss": 0.3086,
      "step": 733
    },
    {
      "epoch": 5.87,
      "grad_norm": 1.5746514797210693,
      "learning_rate": 3.844118389425153e-05,
      "loss": 0.3179,
      "step": 734
    },
    {
      "epoch": 5.88,
      "grad_norm": 1.5033851861953735,
      "learning_rate": 3.831512992967079e-05,
      "loss": 0.2567,
      "step": 735
    },
    {
      "epoch": 5.89,
      "grad_norm": 2.1937642097473145,
      "learning_rate": 3.8189154473855877e-05,
      "loss": 0.3134,
      "step": 736
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.342394232749939,
      "learning_rate": 3.806325837321565e-05,
      "loss": 0.2524,
      "step": 737
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.5976253747940063,
      "learning_rate": 3.7937442473625786e-05,
      "loss": 0.2678,
      "step": 738
    },
    {
      "epoch": 5.91,
      "grad_norm": 1.0898985862731934,
      "learning_rate": 3.7811707620423114e-05,
      "loss": 0.197,
      "step": 739
    },
    {
      "epoch": 5.92,
      "grad_norm": 2.338348627090454,
      "learning_rate": 3.7686054658399935e-05,
      "loss": 0.3934,
      "step": 740
    },
    {
      "epoch": 5.93,
      "grad_norm": 1.8587820529937744,
      "learning_rate": 3.756048443179832e-05,
      "loss": 0.3349,
      "step": 741
    },
    {
      "epoch": 5.94,
      "grad_norm": 1.8252795934677124,
      "learning_rate": 3.743499778430445e-05,
      "loss": 0.3832,
      "step": 742
    },
    {
      "epoch": 5.94,
      "grad_norm": 2.2504348754882812,
      "learning_rate": 3.730959555904298e-05,
      "loss": 0.3913,
      "step": 743
    },
    {
      "epoch": 5.95,
      "grad_norm": 2.1038529872894287,
      "learning_rate": 3.71842785985713e-05,
      "loss": 0.3665,
      "step": 744
    },
    {
      "epoch": 5.96,
      "grad_norm": 2.657421350479126,
      "learning_rate": 3.705904774487396e-05,
      "loss": 0.4234,
      "step": 745
    },
    {
      "epoch": 5.97,
      "grad_norm": 1.5252771377563477,
      "learning_rate": 3.693390383935698e-05,
      "loss": 0.256,
      "step": 746
    },
    {
      "epoch": 5.98,
      "grad_norm": 1.8937594890594482,
      "learning_rate": 3.680884772284212e-05,
      "loss": 0.3419,
      "step": 747
    },
    {
      "epoch": 5.98,
      "grad_norm": 1.8245923519134521,
      "learning_rate": 3.668388023556138e-05,
      "loss": 0.3254,
      "step": 748
    },
    {
      "epoch": 5.99,
      "grad_norm": 1.375982642173767,
      "learning_rate": 3.6559002217151254e-05,
      "loss": 0.2802,
      "step": 749
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.6538490056991577,
      "learning_rate": 3.643421450664706e-05,
      "loss": 0.2881,
      "step": 750
    },
    {
      "epoch": 6.01,
      "grad_norm": 1.2915756702423096,
      "learning_rate": 3.63095179424774e-05,
      "loss": 0.1862,
      "step": 751
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.0244892835617065,
      "learning_rate": 3.618491336245849e-05,
      "loss": 0.2413,
      "step": 752
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.2990753650665283,
      "learning_rate": 3.606040160378848e-05,
      "loss": 0.1975,
      "step": 753
    },
    {
      "epoch": 6.03,
      "grad_norm": 1.364456057548523,
      "learning_rate": 3.5935983503041866e-05,
      "loss": 0.2661,
      "step": 754
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.7758837938308716,
      "learning_rate": 3.581165989616392e-05,
      "loss": 0.2617,
      "step": 755
    },
    {
      "epoch": 6.05,
      "grad_norm": 1.7455809116363525,
      "learning_rate": 3.5687431618464974e-05,
      "loss": 0.2861,
      "step": 756
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.2347365617752075,
      "learning_rate": 3.556329950461488e-05,
      "loss": 0.2396,
      "step": 757
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.346828579902649,
      "learning_rate": 3.5439264388637405e-05,
      "loss": 0.2199,
      "step": 758
    },
    {
      "epoch": 6.07,
      "grad_norm": 1.206687331199646,
      "learning_rate": 3.531532710390455e-05,
      "loss": 0.1932,
      "step": 759
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.546296238899231,
      "learning_rate": 3.519148848313103e-05,
      "loss": 0.2122,
      "step": 760
    },
    {
      "epoch": 6.09,
      "grad_norm": 1.874616026878357,
      "learning_rate": 3.506774935836868e-05,
      "loss": 0.3052,
      "step": 761
    },
    {
      "epoch": 6.1,
      "grad_norm": 1.0199400186538696,
      "learning_rate": 3.494411056100078e-05,
      "loss": 0.1837,
      "step": 762
    },
    {
      "epoch": 6.1,
      "grad_norm": 1.4275938272476196,
      "learning_rate": 3.482057292173658e-05,
      "loss": 0.2287,
      "step": 763
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.9824256896972656,
      "learning_rate": 3.469713727060564e-05,
      "loss": 0.1773,
      "step": 764
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.3851523399353027,
      "learning_rate": 3.457380443695226e-05,
      "loss": 0.208,
      "step": 765
    },
    {
      "epoch": 6.13,
      "grad_norm": 1.2812578678131104,
      "learning_rate": 3.445057524942997e-05,
      "loss": 0.234,
      "step": 766
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.440119743347168,
      "learning_rate": 3.4327450535995906e-05,
      "loss": 0.2067,
      "step": 767
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.3548535108566284,
      "learning_rate": 3.42044311239052e-05,
      "loss": 0.1998,
      "step": 768
    },
    {
      "epoch": 6.15,
      "grad_norm": 1.2885844707489014,
      "learning_rate": 3.408151783970556e-05,
      "loss": 0.197,
      "step": 769
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.4108914136886597,
      "learning_rate": 3.395871150923163e-05,
      "loss": 0.2064,
      "step": 770
    },
    {
      "epoch": 6.17,
      "grad_norm": 1.7725272178649902,
      "learning_rate": 3.3836012957599375e-05,
      "loss": 0.3214,
      "step": 771
    },
    {
      "epoch": 6.18,
      "grad_norm": 2.593393087387085,
      "learning_rate": 3.371342300920071e-05,
      "loss": 0.3051,
      "step": 772
    },
    {
      "epoch": 6.18,
      "grad_norm": 1.681752324104309,
      "learning_rate": 3.359094248769777e-05,
      "loss": 0.2157,
      "step": 773
    },
    {
      "epoch": 6.19,
      "grad_norm": 2.0243451595306396,
      "learning_rate": 3.3468572216017535e-05,
      "loss": 0.2721,
      "step": 774
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.3285759687423706,
      "learning_rate": 3.334631301634623e-05,
      "loss": 0.2106,
      "step": 775
    },
    {
      "epoch": 6.21,
      "grad_norm": 1.6522667407989502,
      "learning_rate": 3.3224165710123756e-05,
      "loss": 0.2584,
      "step": 776
    },
    {
      "epoch": 6.22,
      "grad_norm": 1.563274621963501,
      "learning_rate": 3.310213111803827e-05,
      "loss": 0.2137,
      "step": 777
    },
    {
      "epoch": 6.22,
      "grad_norm": 1.4144327640533447,
      "learning_rate": 3.29802100600206e-05,
      "loss": 0.201,
      "step": 778
    },
    {
      "epoch": 6.23,
      "grad_norm": 1.5466721057891846,
      "learning_rate": 3.2858403355238745e-05,
      "loss": 0.2418,
      "step": 779
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.3746845722198486,
      "learning_rate": 3.2736711822092406e-05,
      "loss": 0.1899,
      "step": 780
    },
    {
      "epoch": 6.25,
      "grad_norm": 1.5345847606658936,
      "learning_rate": 3.261513627820747e-05,
      "loss": 0.2564,
      "step": 781
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.1422414779663086,
      "learning_rate": 3.249367754043047e-05,
      "loss": 0.1987,
      "step": 782
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.5631332397460938,
      "learning_rate": 3.237233642482317e-05,
      "loss": 0.2843,
      "step": 783
    },
    {
      "epoch": 6.27,
      "grad_norm": 2.0212924480438232,
      "learning_rate": 3.225111374665707e-05,
      "loss": 0.3232,
      "step": 784
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.3679721355438232,
      "learning_rate": 3.2130010320407824e-05,
      "loss": 0.1967,
      "step": 785
    },
    {
      "epoch": 6.29,
      "grad_norm": 1.6195088624954224,
      "learning_rate": 3.200902695974995e-05,
      "loss": 0.2496,
      "step": 786
    },
    {
      "epoch": 6.3,
      "grad_norm": 1.6051043272018433,
      "learning_rate": 3.188816447755124e-05,
      "loss": 0.2009,
      "step": 787
    },
    {
      "epoch": 6.3,
      "grad_norm": 1.5961874723434448,
      "learning_rate": 3.176742368586725e-05,
      "loss": 0.2352,
      "step": 788
    },
    {
      "epoch": 6.31,
      "grad_norm": 1.4216022491455078,
      "learning_rate": 3.1646805395935994e-05,
      "loss": 0.2533,
      "step": 789
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.5387423038482666,
      "learning_rate": 3.152631041817244e-05,
      "loss": 0.2232,
      "step": 790
    },
    {
      "epoch": 6.33,
      "grad_norm": 1.4013692140579224,
      "learning_rate": 3.1405939562162937e-05,
      "loss": 0.2149,
      "step": 791
    },
    {
      "epoch": 6.34,
      "grad_norm": 1.5767507553100586,
      "learning_rate": 3.128569363665995e-05,
      "loss": 0.2501,
      "step": 792
    },
    {
      "epoch": 6.34,
      "grad_norm": 1.5294387340545654,
      "learning_rate": 3.116557344957658e-05,
      "loss": 0.2315,
      "step": 793
    },
    {
      "epoch": 6.35,
      "grad_norm": 1.44553804397583,
      "learning_rate": 3.104557980798104e-05,
      "loss": 0.2664,
      "step": 794
    },
    {
      "epoch": 6.36,
      "grad_norm": 1.4877561330795288,
      "learning_rate": 3.092571351809135e-05,
      "loss": 0.2313,
      "step": 795
    },
    {
      "epoch": 6.37,
      "grad_norm": 1.0204368829727173,
      "learning_rate": 3.080597538526988e-05,
      "loss": 0.1956,
      "step": 796
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.7582554817199707,
      "learning_rate": 3.06863662140179e-05,
      "loss": 0.2143,
      "step": 797
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.5700308084487915,
      "learning_rate": 3.056688680797024e-05,
      "loss": 0.2412,
      "step": 798
    },
    {
      "epoch": 6.39,
      "grad_norm": 1.455452561378479,
      "learning_rate": 3.044753796988985e-05,
      "loss": 0.2531,
      "step": 799
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.3628664016723633,
      "learning_rate": 3.032832050166239e-05,
      "loss": 0.2102,
      "step": 800
    },
    {
      "epoch": 6.41,
      "grad_norm": 1.7306110858917236,
      "learning_rate": 3.0209235204290887e-05,
      "loss": 0.2909,
      "step": 801
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.6296206712722778,
      "learning_rate": 3.0090282877890374e-05,
      "loss": 0.2509,
      "step": 802
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.3210241794586182,
      "learning_rate": 2.9971464321682362e-05,
      "loss": 0.253,
      "step": 803
    },
    {
      "epoch": 6.43,
      "grad_norm": 1.4998687505722046,
      "learning_rate": 2.9852780333989704e-05,
      "loss": 0.2395,
      "step": 804
    },
    {
      "epoch": 6.44,
      "grad_norm": 1.2772432565689087,
      "learning_rate": 2.973423171223107e-05,
      "loss": 0.1973,
      "step": 805
    },
    {
      "epoch": 6.45,
      "grad_norm": 1.2049126625061035,
      "learning_rate": 2.9615819252915565e-05,
      "loss": 0.1885,
      "step": 806
    },
    {
      "epoch": 6.46,
      "grad_norm": 1.583712100982666,
      "learning_rate": 2.9497543751637506e-05,
      "loss": 0.2463,
      "step": 807
    },
    {
      "epoch": 6.46,
      "grad_norm": 1.383951187133789,
      "learning_rate": 2.9379406003071035e-05,
      "loss": 0.2329,
      "step": 808
    },
    {
      "epoch": 6.47,
      "grad_norm": 1.580391764640808,
      "learning_rate": 2.9261406800964662e-05,
      "loss": 0.2439,
      "step": 809
    },
    {
      "epoch": 6.48,
      "grad_norm": 1.7472821474075317,
      "learning_rate": 2.914354693813609e-05,
      "loss": 0.265,
      "step": 810
    },
    {
      "epoch": 6.49,
      "grad_norm": 1.3222713470458984,
      "learning_rate": 2.902582720646685e-05,
      "loss": 0.2379,
      "step": 811
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.3993507623672485,
      "learning_rate": 2.890824839689689e-05,
      "loss": 0.1963,
      "step": 812
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.1791887283325195,
      "learning_rate": 2.8790811299419336e-05,
      "loss": 0.272,
      "step": 813
    },
    {
      "epoch": 6.51,
      "grad_norm": 1.3866084814071655,
      "learning_rate": 2.867351670307525e-05,
      "loss": 0.2272,
      "step": 814
    },
    {
      "epoch": 6.52,
      "grad_norm": 1.5016127824783325,
      "learning_rate": 2.8556365395948103e-05,
      "loss": 0.2212,
      "step": 815
    },
    {
      "epoch": 6.53,
      "grad_norm": 1.4126410484313965,
      "learning_rate": 2.843935816515877e-05,
      "loss": 0.2239,
      "step": 816
    },
    {
      "epoch": 6.54,
      "grad_norm": 1.1594594717025757,
      "learning_rate": 2.8322495796860084e-05,
      "loss": 0.2567,
      "step": 817
    },
    {
      "epoch": 6.54,
      "grad_norm": 1.3422821760177612,
      "learning_rate": 2.8205779076231447e-05,
      "loss": 0.2434,
      "step": 818
    },
    {
      "epoch": 6.55,
      "grad_norm": 1.3650970458984375,
      "learning_rate": 2.808920878747381e-05,
      "loss": 0.1964,
      "step": 819
    },
    {
      "epoch": 6.56,
      "grad_norm": 1.7883799076080322,
      "learning_rate": 2.7972785713804263e-05,
      "loss": 0.2278,
      "step": 820
    },
    {
      "epoch": 6.57,
      "grad_norm": 1.2991477251052856,
      "learning_rate": 2.7856510637450668e-05,
      "loss": 0.1556,
      "step": 821
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.6267833709716797,
      "learning_rate": 2.774038433964665e-05,
      "loss": 0.2427,
      "step": 822
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.4986404180526733,
      "learning_rate": 2.7624407600626145e-05,
      "loss": 0.2453,
      "step": 823
    },
    {
      "epoch": 6.59,
      "grad_norm": 1.4782882928848267,
      "learning_rate": 2.750858119961821e-05,
      "loss": 0.239,
      "step": 824
    },
    {
      "epoch": 6.6,
      "grad_norm": 1.3273321390151978,
      "learning_rate": 2.7392905914841882e-05,
      "loss": 0.2083,
      "step": 825
    },
    {
      "epoch": 6.61,
      "grad_norm": 1.451256513595581,
      "learning_rate": 2.7277382523500807e-05,
      "loss": 0.2332,
      "step": 826
    },
    {
      "epoch": 6.62,
      "grad_norm": 1.6663371324539185,
      "learning_rate": 2.7162011801778076e-05,
      "loss": 0.2392,
      "step": 827
    },
    {
      "epoch": 6.62,
      "grad_norm": 1.5866844654083252,
      "learning_rate": 2.7046794524831088e-05,
      "loss": 0.2683,
      "step": 828
    },
    {
      "epoch": 6.63,
      "grad_norm": 1.9296159744262695,
      "learning_rate": 2.693173146678621e-05,
      "loss": 0.2948,
      "step": 829
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.624173879623413,
      "learning_rate": 2.6816823400733625e-05,
      "loss": 0.2521,
      "step": 830
    },
    {
      "epoch": 6.65,
      "grad_norm": 1.330336332321167,
      "learning_rate": 2.6702071098722253e-05,
      "loss": 0.1861,
      "step": 831
    },
    {
      "epoch": 6.66,
      "grad_norm": 2.255384683609009,
      "learning_rate": 2.65874753317543e-05,
      "loss": 0.2485,
      "step": 832
    },
    {
      "epoch": 6.66,
      "grad_norm": 1.2840808629989624,
      "learning_rate": 2.6473036869780353e-05,
      "loss": 0.1781,
      "step": 833
    },
    {
      "epoch": 6.67,
      "grad_norm": 1.5879734754562378,
      "learning_rate": 2.6358756481694114e-05,
      "loss": 0.2062,
      "step": 834
    },
    {
      "epoch": 6.68,
      "grad_norm": 1.6700516939163208,
      "learning_rate": 2.6244634935327085e-05,
      "loss": 0.2,
      "step": 835
    },
    {
      "epoch": 6.69,
      "grad_norm": 1.7062982320785522,
      "learning_rate": 2.613067299744364e-05,
      "loss": 0.2393,
      "step": 836
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.1936769485473633,
      "learning_rate": 2.601687143373579e-05,
      "loss": 0.1769,
      "step": 837
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.6837103366851807,
      "learning_rate": 2.5903231008817885e-05,
      "loss": 0.2276,
      "step": 838
    },
    {
      "epoch": 6.71,
      "grad_norm": 1.953670620918274,
      "learning_rate": 2.578975248622175e-05,
      "loss": 0.2012,
      "step": 839
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.8382441997528076,
      "learning_rate": 2.5676436628391354e-05,
      "loss": 0.2374,
      "step": 840
    },
    {
      "epoch": 6.73,
      "grad_norm": 1.653095006942749,
      "learning_rate": 2.5563284196677716e-05,
      "loss": 0.2294,
      "step": 841
    },
    {
      "epoch": 6.74,
      "grad_norm": 1.4489470720291138,
      "learning_rate": 2.5450295951333896e-05,
      "loss": 0.1979,
      "step": 842
    },
    {
      "epoch": 6.74,
      "grad_norm": 1.4571566581726074,
      "learning_rate": 2.5337472651509763e-05,
      "loss": 0.2061,
      "step": 843
    },
    {
      "epoch": 6.75,
      "grad_norm": 1.5860157012939453,
      "learning_rate": 2.5224815055246918e-05,
      "loss": 0.2453,
      "step": 844
    },
    {
      "epoch": 6.76,
      "grad_norm": 1.5210249423980713,
      "learning_rate": 2.511232391947372e-05,
      "loss": 0.2395,
      "step": 845
    },
    {
      "epoch": 6.77,
      "grad_norm": 1.737520456314087,
      "learning_rate": 2.500000000000001e-05,
      "loss": 0.2433,
      "step": 846
    },
    {
      "epoch": 6.78,
      "grad_norm": 2.0702426433563232,
      "learning_rate": 2.488784405151216e-05,
      "loss": 0.2947,
      "step": 847
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.5749807357788086,
      "learning_rate": 2.4775856827568016e-05,
      "loss": 0.2311,
      "step": 848
    },
    {
      "epoch": 6.79,
      "grad_norm": 1.8360999822616577,
      "learning_rate": 2.4664039080591732e-05,
      "loss": 0.292,
      "step": 849
    },
    {
      "epoch": 6.8,
      "grad_norm": 1.4885200262069702,
      "learning_rate": 2.4552391561868783e-05,
      "loss": 0.2389,
      "step": 850
    },
    {
      "epoch": 6.81,
      "grad_norm": 1.4713976383209229,
      "learning_rate": 2.444091502154095e-05,
      "loss": 0.2011,
      "step": 851
    },
    {
      "epoch": 6.82,
      "grad_norm": 1.714979887008667,
      "learning_rate": 2.4329610208601195e-05,
      "loss": 0.2119,
      "step": 852
    },
    {
      "epoch": 6.82,
      "grad_norm": 1.4002326726913452,
      "learning_rate": 2.4218477870888684e-05,
      "loss": 0.1996,
      "step": 853
    },
    {
      "epoch": 6.83,
      "grad_norm": 1.5724115371704102,
      "learning_rate": 2.410751875508373e-05,
      "loss": 0.2256,
      "step": 854
    },
    {
      "epoch": 6.84,
      "grad_norm": 1.7789132595062256,
      "learning_rate": 2.3996733606702853e-05,
      "loss": 0.2967,
      "step": 855
    },
    {
      "epoch": 6.85,
      "grad_norm": 1.5412966012954712,
      "learning_rate": 2.388612317009366e-05,
      "loss": 0.2566,
      "step": 856
    },
    {
      "epoch": 6.86,
      "grad_norm": 1.6569949388504028,
      "learning_rate": 2.3775688188429896e-05,
      "loss": 0.2638,
      "step": 857
    },
    {
      "epoch": 6.86,
      "grad_norm": 1.2961318492889404,
      "learning_rate": 2.3665429403706506e-05,
      "loss": 0.1857,
      "step": 858
    },
    {
      "epoch": 6.87,
      "grad_norm": 1.5302600860595703,
      "learning_rate": 2.3555347556734542e-05,
      "loss": 0.2423,
      "step": 859
    },
    {
      "epoch": 6.88,
      "grad_norm": 1.30540931224823,
      "learning_rate": 2.3445443387136244e-05,
      "loss": 0.2367,
      "step": 860
    },
    {
      "epoch": 6.89,
      "grad_norm": 1.5170799493789673,
      "learning_rate": 2.3335717633340108e-05,
      "loss": 0.2085,
      "step": 861
    },
    {
      "epoch": 6.9,
      "grad_norm": 1.8484560251235962,
      "learning_rate": 2.3226171032575856e-05,
      "loss": 0.2864,
      "step": 862
    },
    {
      "epoch": 6.9,
      "grad_norm": 1.47430419921875,
      "learning_rate": 2.3116804320869467e-05,
      "loss": 0.2444,
      "step": 863
    },
    {
      "epoch": 6.91,
      "grad_norm": 1.3665626049041748,
      "learning_rate": 2.3007618233038373e-05,
      "loss": 0.2291,
      "step": 864
    },
    {
      "epoch": 6.92,
      "grad_norm": 1.5631325244903564,
      "learning_rate": 2.289861350268634e-05,
      "loss": 0.2472,
      "step": 865
    },
    {
      "epoch": 6.93,
      "grad_norm": 1.202075719833374,
      "learning_rate": 2.2789790862198628e-05,
      "loss": 0.1917,
      "step": 866
    },
    {
      "epoch": 6.94,
      "grad_norm": 1.4996752738952637,
      "learning_rate": 2.2681151042737127e-05,
      "loss": 0.2041,
      "step": 867
    },
    {
      "epoch": 6.94,
      "grad_norm": 1.4757667779922485,
      "learning_rate": 2.257269477423532e-05,
      "loss": 0.2201,
      "step": 868
    },
    {
      "epoch": 6.95,
      "grad_norm": 1.4270814657211304,
      "learning_rate": 2.246442278539344e-05,
      "loss": 0.2307,
      "step": 869
    },
    {
      "epoch": 6.96,
      "grad_norm": 1.723956823348999,
      "learning_rate": 2.2356335803673656e-05,
      "loss": 0.2592,
      "step": 870
    },
    {
      "epoch": 6.97,
      "grad_norm": 2.1586008071899414,
      "learning_rate": 2.224843455529496e-05,
      "loss": 0.2289,
      "step": 871
    },
    {
      "epoch": 6.98,
      "grad_norm": 1.6606247425079346,
      "learning_rate": 2.2140719765228584e-05,
      "loss": 0.2557,
      "step": 872
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.00339937210083,
      "learning_rate": 2.203319215719288e-05,
      "loss": 0.2366,
      "step": 873
    },
    {
      "epoch": 6.99,
      "grad_norm": 1.4323207139968872,
      "learning_rate": 2.192585245364856e-05,
      "loss": 0.2427,
      "step": 874
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.4030101299285889,
      "learning_rate": 2.18187013757939e-05,
      "loss": 0.2076,
      "step": 875
    },
    {
      "epoch": 7.01,
      "grad_norm": 1.4033406972885132,
      "learning_rate": 2.1711739643559764e-05,
      "loss": 0.1571,
      "step": 876
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.198781132698059,
      "learning_rate": 2.1604967975604844e-05,
      "loss": 0.1921,
      "step": 877
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.2226499319076538,
      "learning_rate": 2.1498387089310868e-05,
      "loss": 0.1834,
      "step": 878
    },
    {
      "epoch": 7.03,
      "grad_norm": 1.4989796876907349,
      "learning_rate": 2.139199770077768e-05,
      "loss": 0.2176,
      "step": 879
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.367092490196228,
      "learning_rate": 2.128580052481848e-05,
      "loss": 0.1855,
      "step": 880
    },
    {
      "epoch": 7.05,
      "grad_norm": 1.4187359809875488,
      "learning_rate": 2.1179796274955073e-05,
      "loss": 0.179,
      "step": 881
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.1986676454544067,
      "learning_rate": 2.1073985663412983e-05,
      "loss": 0.142,
      "step": 882
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.3514353036880493,
      "learning_rate": 2.0968369401116693e-05,
      "loss": 0.1671,
      "step": 883
    },
    {
      "epoch": 7.07,
      "grad_norm": 1.346440315246582,
      "learning_rate": 2.0862948197684955e-05,
      "loss": 0.1939,
      "step": 884
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.2621891498565674,
      "learning_rate": 2.0757722761425892e-05,
      "loss": 0.1261,
      "step": 885
    },
    {
      "epoch": 7.09,
      "grad_norm": 1.346102237701416,
      "learning_rate": 2.0652693799332284e-05,
      "loss": 0.181,
      "step": 886
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.3555517196655273,
      "learning_rate": 2.054786201707693e-05,
      "loss": 0.1903,
      "step": 887
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.1845790147781372,
      "learning_rate": 2.044322811900767e-05,
      "loss": 0.1472,
      "step": 888
    },
    {
      "epoch": 7.11,
      "grad_norm": 1.2933579683303833,
      "learning_rate": 2.0338792808142887e-05,
      "loss": 0.1522,
      "step": 889
    },
    {
      "epoch": 7.12,
      "grad_norm": 1.5339293479919434,
      "learning_rate": 2.0234556786166715e-05,
      "loss": 0.1958,
      "step": 890
    },
    {
      "epoch": 7.13,
      "grad_norm": 1.1526883840560913,
      "learning_rate": 2.0130520753424176e-05,
      "loss": 0.136,
      "step": 891
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.4658324718475342,
      "learning_rate": 2.00266854089167e-05,
      "loss": 0.1885,
      "step": 892
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.3186397552490234,
      "learning_rate": 1.9923051450297336e-05,
      "loss": 0.1943,
      "step": 893
    },
    {
      "epoch": 7.15,
      "grad_norm": 1.4703868627548218,
      "learning_rate": 1.9819619573865934e-05,
      "loss": 0.1844,
      "step": 894
    },
    {
      "epoch": 7.16,
      "grad_norm": 1.3142931461334229,
      "learning_rate": 1.971639047456473e-05,
      "loss": 0.171,
      "step": 895
    },
    {
      "epoch": 7.17,
      "grad_norm": 1.6928242444992065,
      "learning_rate": 1.961336484597343e-05,
      "loss": 0.1532,
      "step": 896
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.4281060695648193,
      "learning_rate": 1.9510543380304685e-05,
      "loss": 0.1714,
      "step": 897
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.4549872875213623,
      "learning_rate": 1.9407926768399452e-05,
      "loss": 0.1962,
      "step": 898
    },
    {
      "epoch": 7.19,
      "grad_norm": 1.1183903217315674,
      "learning_rate": 1.9305515699722243e-05,
      "loss": 0.1633,
      "step": 899
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.539002537727356,
      "learning_rate": 1.9203310862356577e-05,
      "loss": 0.1747,
      "step": 900
    },
    {
      "epoch": 7.21,
      "grad_norm": 1.1619726419448853,
      "learning_rate": 1.910131294300037e-05,
      "loss": 0.1628,
      "step": 901
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.4881908893585205,
      "learning_rate": 1.899952262696125e-05,
      "loss": 0.1779,
      "step": 902
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.3066272735595703,
      "learning_rate": 1.8897940598151998e-05,
      "loss": 0.1839,
      "step": 903
    },
    {
      "epoch": 7.23,
      "grad_norm": 1.4632683992385864,
      "learning_rate": 1.879656753908598e-05,
      "loss": 0.2244,
      "step": 904
    },
    {
      "epoch": 7.24,
      "grad_norm": 1.3231194019317627,
      "learning_rate": 1.869540413087249e-05,
      "loss": 0.2219,
      "step": 905
    },
    {
      "epoch": 7.25,
      "grad_norm": 1.4372611045837402,
      "learning_rate": 1.8594451053212208e-05,
      "loss": 0.1997,
      "step": 906
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.5602234601974487,
      "learning_rate": 1.8493708984392683e-05,
      "loss": 0.2003,
      "step": 907
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.600313425064087,
      "learning_rate": 1.8393178601283683e-05,
      "loss": 0.1925,
      "step": 908
    },
    {
      "epoch": 7.27,
      "grad_norm": 1.4369406700134277,
      "learning_rate": 1.8292860579332704e-05,
      "loss": 0.2053,
      "step": 909
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.6741199493408203,
      "learning_rate": 1.8192755592560445e-05,
      "loss": 0.2588,
      "step": 910
    },
    {
      "epoch": 7.29,
      "grad_norm": 1.4135866165161133,
      "learning_rate": 1.8092864313556234e-05,
      "loss": 0.2108,
      "step": 911
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.1640716791152954,
      "learning_rate": 1.7993187413473533e-05,
      "loss": 0.1544,
      "step": 912
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.3293745517730713,
      "learning_rate": 1.7893725562025415e-05,
      "loss": 0.1925,
      "step": 913
    },
    {
      "epoch": 7.31,
      "grad_norm": 1.288578987121582,
      "learning_rate": 1.7794479427480117e-05,
      "loss": 0.1446,
      "step": 914
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.46493661403656,
      "learning_rate": 1.769544967665647e-05,
      "loss": 0.2071,
      "step": 915
    },
    {
      "epoch": 7.33,
      "grad_norm": 1.2271379232406616,
      "learning_rate": 1.759663697491944e-05,
      "loss": 0.1751,
      "step": 916
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.495883584022522,
      "learning_rate": 1.7498041986175757e-05,
      "loss": 0.1629,
      "step": 917
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.77277410030365,
      "learning_rate": 1.739966537286929e-05,
      "loss": 0.1543,
      "step": 918
    },
    {
      "epoch": 7.35,
      "grad_norm": 1.5014503002166748,
      "learning_rate": 1.7301507795976697e-05,
      "loss": 0.204,
      "step": 919
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.2732030153274536,
      "learning_rate": 1.7203569915003005e-05,
      "loss": 0.1418,
      "step": 920
    },
    {
      "epoch": 7.37,
      "grad_norm": 1.9128904342651367,
      "learning_rate": 1.7105852387977096e-05,
      "loss": 0.239,
      "step": 921
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.5101253986358643,
      "learning_rate": 1.7008355871447345e-05,
      "loss": 0.1898,
      "step": 922
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.3650128841400146,
      "learning_rate": 1.6911081020477177e-05,
      "loss": 0.1303,
      "step": 923
    },
    {
      "epoch": 7.39,
      "grad_norm": 1.6354103088378906,
      "learning_rate": 1.6814028488640726e-05,
      "loss": 0.1651,
      "step": 924
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.5141829252243042,
      "learning_rate": 1.671719892801835e-05,
      "loss": 0.1581,
      "step": 925
    },
    {
      "epoch": 7.41,
      "grad_norm": 1.3092072010040283,
      "learning_rate": 1.662059298919232e-05,
      "loss": 0.1791,
      "step": 926
    },
    {
      "epoch": 7.42,
      "grad_norm": 1.5521256923675537,
      "learning_rate": 1.6524211321242443e-05,
      "loss": 0.1958,
      "step": 927
    },
    {
      "epoch": 7.42,
      "grad_norm": 1.376948595046997,
      "learning_rate": 1.642805457174166e-05,
      "loss": 0.1746,
      "step": 928
    },
    {
      "epoch": 7.43,
      "grad_norm": 1.448306679725647,
      "learning_rate": 1.633212338675173e-05,
      "loss": 0.1815,
      "step": 929
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.4884291887283325,
      "learning_rate": 1.6236418410818872e-05,
      "loss": 0.1627,
      "step": 930
    },
    {
      "epoch": 7.45,
      "grad_norm": 1.1785398721694946,
      "learning_rate": 1.6140940286969476e-05,
      "loss": 0.1414,
      "step": 931
    },
    {
      "epoch": 7.46,
      "grad_norm": 1.4589481353759766,
      "learning_rate": 1.6045689656705716e-05,
      "loss": 0.1404,
      "step": 932
    },
    {
      "epoch": 7.46,
      "grad_norm": 1.2152132987976074,
      "learning_rate": 1.595066716000126e-05,
      "loss": 0.1583,
      "step": 933
    },
    {
      "epoch": 7.47,
      "grad_norm": 1.4357571601867676,
      "learning_rate": 1.5855873435297043e-05,
      "loss": 0.1576,
      "step": 934
    },
    {
      "epoch": 7.48,
      "grad_norm": 1.3762520551681519,
      "learning_rate": 1.5761309119496863e-05,
      "loss": 0.1631,
      "step": 935
    },
    {
      "epoch": 7.49,
      "grad_norm": 1.9642977714538574,
      "learning_rate": 1.5666974847963162e-05,
      "loss": 0.2589,
      "step": 936
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.3793314695358276,
      "learning_rate": 1.557287125451279e-05,
      "loss": 0.1828,
      "step": 937
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.2820825576782227,
      "learning_rate": 1.5478998971412668e-05,
      "loss": 0.15,
      "step": 938
    },
    {
      "epoch": 7.51,
      "grad_norm": 1.441785216331482,
      "learning_rate": 1.538535862937558e-05,
      "loss": 0.2197,
      "step": 939
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.4430211782455444,
      "learning_rate": 1.529195085755598e-05,
      "loss": 0.1718,
      "step": 940
    },
    {
      "epoch": 7.53,
      "grad_norm": 1.655078649520874,
      "learning_rate": 1.5198776283545668e-05,
      "loss": 0.1908,
      "step": 941
    },
    {
      "epoch": 7.54,
      "grad_norm": 1.3835288286209106,
      "learning_rate": 1.510583553336964e-05,
      "loss": 0.1698,
      "step": 942
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.115509033203125,
      "learning_rate": 1.5013129231481893e-05,
      "loss": 0.2058,
      "step": 943
    },
    {
      "epoch": 7.55,
      "grad_norm": 1.224595308303833,
      "learning_rate": 1.4920658000761174e-05,
      "loss": 0.1608,
      "step": 944
    },
    {
      "epoch": 7.56,
      "grad_norm": 1.4354588985443115,
      "learning_rate": 1.4828422462506818e-05,
      "loss": 0.1479,
      "step": 945
    },
    {
      "epoch": 7.57,
      "grad_norm": 1.689339518547058,
      "learning_rate": 1.4736423236434649e-05,
      "loss": 0.1743,
      "step": 946
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.3278175592422485,
      "learning_rate": 1.4644660940672627e-05,
      "loss": 0.1666,
      "step": 947
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.2820987701416016,
      "learning_rate": 1.4553136191756917e-05,
      "loss": 0.158,
      "step": 948
    },
    {
      "epoch": 7.59,
      "grad_norm": 1.3717467784881592,
      "learning_rate": 1.4461849604627642e-05,
      "loss": 0.1921,
      "step": 949
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.3958020210266113,
      "learning_rate": 1.4370801792624656e-05,
      "loss": 0.1991,
      "step": 950
    },
    {
      "epoch": 7.61,
      "grad_norm": 1.3946127891540527,
      "learning_rate": 1.4279993367483641e-05,
      "loss": 0.1845,
      "step": 951
    },
    {
      "epoch": 7.62,
      "grad_norm": 1.4647669792175293,
      "learning_rate": 1.4189424939331814e-05,
      "loss": 0.1938,
      "step": 952
    },
    {
      "epoch": 7.62,
      "grad_norm": 1.11949622631073,
      "learning_rate": 1.4099097116683874e-05,
      "loss": 0.1379,
      "step": 953
    },
    {
      "epoch": 7.63,
      "grad_norm": 1.5886908769607544,
      "learning_rate": 1.4009010506437997e-05,
      "loss": 0.2129,
      "step": 954
    },
    {
      "epoch": 7.64,
      "grad_norm": 1.1492098569869995,
      "learning_rate": 1.3919165713871641e-05,
      "loss": 0.129,
      "step": 955
    },
    {
      "epoch": 7.65,
      "grad_norm": 1.7912955284118652,
      "learning_rate": 1.3829563342637513e-05,
      "loss": 0.2032,
      "step": 956
    },
    {
      "epoch": 7.66,
      "grad_norm": 1.5632426738739014,
      "learning_rate": 1.3740203994759599e-05,
      "loss": 0.182,
      "step": 957
    },
    {
      "epoch": 7.66,
      "grad_norm": 1.130683422088623,
      "learning_rate": 1.3651088270628993e-05,
      "loss": 0.1076,
      "step": 958
    },
    {
      "epoch": 7.67,
      "grad_norm": 1.4820172786712646,
      "learning_rate": 1.356221676899992e-05,
      "loss": 0.173,
      "step": 959
    },
    {
      "epoch": 7.68,
      "grad_norm": 1.294271469116211,
      "learning_rate": 1.3473590086985754e-05,
      "loss": 0.1441,
      "step": 960
    },
    {
      "epoch": 7.69,
      "grad_norm": 1.3754277229309082,
      "learning_rate": 1.338520882005494e-05,
      "loss": 0.1437,
      "step": 961
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.3746901750564575,
      "learning_rate": 1.329707356202699e-05,
      "loss": 0.1491,
      "step": 962
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.3794224262237549,
      "learning_rate": 1.3209184905068594e-05,
      "loss": 0.1797,
      "step": 963
    },
    {
      "epoch": 7.71,
      "grad_norm": 1.410069465637207,
      "learning_rate": 1.31215434396895e-05,
      "loss": 0.1881,
      "step": 964
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.3126808404922485,
      "learning_rate": 1.3034149754738633e-05,
      "loss": 0.1754,
      "step": 965
    },
    {
      "epoch": 7.73,
      "grad_norm": 1.3600361347198486,
      "learning_rate": 1.2947004437400163e-05,
      "loss": 0.1679,
      "step": 966
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.3415002822875977,
      "learning_rate": 1.2860108073189458e-05,
      "loss": 0.1079,
      "step": 967
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.3555867671966553,
      "learning_rate": 1.2773461245949247e-05,
      "loss": 0.199,
      "step": 968
    },
    {
      "epoch": 7.75,
      "grad_norm": 1.4673436880111694,
      "learning_rate": 1.2687064537845632e-05,
      "loss": 0.1473,
      "step": 969
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.0884829759597778,
      "learning_rate": 1.2600918529364253e-05,
      "loss": 0.1402,
      "step": 970
    },
    {
      "epoch": 7.77,
      "grad_norm": 1.3728914260864258,
      "learning_rate": 1.251502379930629e-05,
      "loss": 0.2174,
      "step": 971
    },
    {
      "epoch": 7.78,
      "grad_norm": 1.5948323011398315,
      "learning_rate": 1.242938092478464e-05,
      "loss": 0.1929,
      "step": 972
    },
    {
      "epoch": 7.78,
      "grad_norm": 1.6654099225997925,
      "learning_rate": 1.2343990481220036e-05,
      "loss": 0.1688,
      "step": 973
    },
    {
      "epoch": 7.79,
      "grad_norm": 1.3912447690963745,
      "learning_rate": 1.225885304233716e-05,
      "loss": 0.1917,
      "step": 974
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.1798352003097534,
      "learning_rate": 1.2173969180160783e-05,
      "loss": 0.1268,
      "step": 975
    },
    {
      "epoch": 7.81,
      "grad_norm": 1.3717763423919678,
      "learning_rate": 1.2089339465011935e-05,
      "loss": 0.1679,
      "step": 976
    },
    {
      "epoch": 7.82,
      "grad_norm": 1.5937254428863525,
      "learning_rate": 1.200496446550411e-05,
      "loss": 0.1975,
      "step": 977
    },
    {
      "epoch": 7.82,
      "grad_norm": 1.6395896673202515,
      "learning_rate": 1.1920844748539373e-05,
      "loss": 0.1644,
      "step": 978
    },
    {
      "epoch": 7.83,
      "grad_norm": 1.7675175666809082,
      "learning_rate": 1.1836980879304576e-05,
      "loss": 0.2294,
      "step": 979
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.4689393043518066,
      "learning_rate": 1.1753373421267621e-05,
      "loss": 0.1408,
      "step": 980
    },
    {
      "epoch": 7.85,
      "grad_norm": 1.9793031215667725,
      "learning_rate": 1.1670022936173585e-05,
      "loss": 0.171,
      "step": 981
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.7156751155853271,
      "learning_rate": 1.1586929984040972e-05,
      "loss": 0.1774,
      "step": 982
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.3481138944625854,
      "learning_rate": 1.1504095123158015e-05,
      "loss": 0.1558,
      "step": 983
    },
    {
      "epoch": 7.87,
      "grad_norm": 1.2502249479293823,
      "learning_rate": 1.1421518910078838e-05,
      "loss": 0.1657,
      "step": 984
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.7274514436721802,
      "learning_rate": 1.133920189961975e-05,
      "loss": 0.2124,
      "step": 985
    },
    {
      "epoch": 7.89,
      "grad_norm": 1.305322527885437,
      "learning_rate": 1.125714464485551e-05,
      "loss": 0.1757,
      "step": 986
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.6958087682724,
      "learning_rate": 1.1175347697115673e-05,
      "loss": 0.1974,
      "step": 987
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.1771273612976074,
      "learning_rate": 1.1093811605980781e-05,
      "loss": 0.1698,
      "step": 988
    },
    {
      "epoch": 7.91,
      "grad_norm": 1.5738554000854492,
      "learning_rate": 1.1012536919278727e-05,
      "loss": 0.209,
      "step": 989
    },
    {
      "epoch": 7.92,
      "grad_norm": 1.4121867418289185,
      "learning_rate": 1.0931524183081104e-05,
      "loss": 0.1565,
      "step": 990
    },
    {
      "epoch": 7.93,
      "grad_norm": 1.3591443300247192,
      "learning_rate": 1.0850773941699461e-05,
      "loss": 0.1993,
      "step": 991
    },
    {
      "epoch": 7.94,
      "grad_norm": 1.820911169052124,
      "learning_rate": 1.0770286737681701e-05,
      "loss": 0.197,
      "step": 992
    },
    {
      "epoch": 7.94,
      "grad_norm": 1.1852384805679321,
      "learning_rate": 1.0690063111808446e-05,
      "loss": 0.1658,
      "step": 993
    },
    {
      "epoch": 7.95,
      "grad_norm": 1.597306251525879,
      "learning_rate": 1.0610103603089344e-05,
      "loss": 0.2186,
      "step": 994
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.66153883934021,
      "learning_rate": 1.0530408748759485e-05,
      "loss": 0.1581,
      "step": 995
    },
    {
      "epoch": 7.97,
      "grad_norm": 1.5451747179031372,
      "learning_rate": 1.0450979084275819e-05,
      "loss": 0.1787,
      "step": 996
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.7888569831848145,
      "learning_rate": 1.0371815143313501e-05,
      "loss": 0.2148,
      "step": 997
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.2466497421264648,
      "learning_rate": 1.0292917457762325e-05,
      "loss": 0.1415,
      "step": 998
    },
    {
      "epoch": 7.99,
      "grad_norm": 1.474673867225647,
      "learning_rate": 1.0214286557723196e-05,
      "loss": 0.1961,
      "step": 999
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.3795088529586792,
      "learning_rate": 1.013592297150449e-05,
      "loss": 0.174,
      "step": 1000
    },
    {
      "epoch": 8.01,
      "grad_norm": 1.2100549936294556,
      "learning_rate": 1.0057827225618555e-05,
      "loss": 0.1196,
      "step": 1001
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.907699465751648,
      "learning_rate": 9.979999844778205e-06,
      "loss": 0.1296,
      "step": 1002
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.158620834350586,
      "learning_rate": 9.90244135189306e-06,
      "loss": 0.1074,
      "step": 1003
    },
    {
      "epoch": 8.03,
      "grad_norm": 1.0981343984603882,
      "learning_rate": 9.825152268066213e-06,
      "loss": 0.1569,
      "step": 1004
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.512951135635376,
      "learning_rate": 9.748133112590624e-06,
      "loss": 0.1497,
      "step": 1005
    },
    {
      "epoch": 8.05,
      "grad_norm": 1.0596811771392822,
      "learning_rate": 9.671384402945589e-06,
      "loss": 0.1051,
      "step": 1006
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.2596186399459839,
      "learning_rate": 9.59490665479339e-06,
      "loss": 0.1336,
      "step": 1007
    },
    {
      "epoch": 8.06,
      "grad_norm": 0.8236064910888672,
      "learning_rate": 9.518700381975754e-06,
      "loss": 0.0899,
      "step": 1008
    },
    {
      "epoch": 8.07,
      "grad_norm": 1.4360800981521606,
      "learning_rate": 9.442766096510352e-06,
      "loss": 0.1715,
      "step": 1009
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.3506125211715698,
      "learning_rate": 9.367104308587494e-06,
      "loss": 0.1882,
      "step": 1010
    },
    {
      "epoch": 8.09,
      "grad_norm": 1.1605594158172607,
      "learning_rate": 9.291715526566564e-06,
      "loss": 0.1153,
      "step": 1011
    },
    {
      "epoch": 8.1,
      "grad_norm": 1.766797423362732,
      "learning_rate": 9.216600256972668e-06,
      "loss": 0.1657,
      "step": 1012
    },
    {
      "epoch": 8.1,
      "grad_norm": 1.0240305662155151,
      "learning_rate": 9.141759004493283e-06,
      "loss": 0.092,
      "step": 1013
    },
    {
      "epoch": 8.11,
      "grad_norm": 1.6934720277786255,
      "learning_rate": 9.067192271974739e-06,
      "loss": 0.1649,
      "step": 1014
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.3515180349349976,
      "learning_rate": 8.992900560418933e-06,
      "loss": 0.1298,
      "step": 1015
    },
    {
      "epoch": 8.13,
      "grad_norm": 1.4614973068237305,
      "learning_rate": 8.91888436897997e-06,
      "loss": 0.1864,
      "step": 1016
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.4455949068069458,
      "learning_rate": 8.845144194960747e-06,
      "loss": 0.1796,
      "step": 1017
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.4455949068069458,
      "learning_rate": 8.845144194960747e-06,
      "loss": 0.1178,
      "step": 1018
    },
    {
      "epoch": 8.15,
      "grad_norm": 1.2849879264831543,
      "learning_rate": 8.771680533809635e-06,
      "loss": 0.1061,
      "step": 1019
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.2050007581710815,
      "learning_rate": 8.69849387911721e-06,
      "loss": 0.1663,
      "step": 1020
    },
    {
      "epoch": 8.17,
      "grad_norm": 1.319183588027954,
      "learning_rate": 8.625584722612829e-06,
      "loss": 0.1295,
      "step": 1021
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.1318893432617188,
      "learning_rate": 8.552953554161408e-06,
      "loss": 0.1266,
      "step": 1022
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.2852150201797485,
      "learning_rate": 8.480600861760124e-06,
      "loss": 0.1749,
      "step": 1023
    },
    {
      "epoch": 8.19,
      "grad_norm": 1.804139494895935,
      "learning_rate": 8.408527131535087e-06,
      "loss": 0.1832,
      "step": 1024
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.6154813766479492,
      "learning_rate": 8.336732847738116e-06,
      "loss": 0.1547,
      "step": 1025
    },
    {
      "epoch": 8.21,
      "grad_norm": 1.3698526620864868,
      "learning_rate": 8.265218492743498e-06,
      "loss": 0.1348,
      "step": 1026
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.4529820680618286,
      "learning_rate": 8.193984547044658e-06,
      "loss": 0.1235,
      "step": 1027
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.0587292909622192,
      "learning_rate": 8.123031489251082e-06,
      "loss": 0.1078,
      "step": 1028
    },
    {
      "epoch": 8.23,
      "grad_norm": 1.135233998298645,
      "learning_rate": 8.052359796084951e-06,
      "loss": 0.135,
      "step": 1029
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.0949021577835083,
      "learning_rate": 7.981969942378021e-06,
      "loss": 0.088,
      "step": 1030
    },
    {
      "epoch": 8.25,
      "grad_norm": 1.4783166646957397,
      "learning_rate": 7.911862401068433e-06,
      "loss": 0.1516,
      "step": 1031
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.3829094171524048,
      "learning_rate": 7.842037643197492e-06,
      "loss": 0.1355,
      "step": 1032
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.4812968969345093,
      "learning_rate": 7.772496137906526e-06,
      "loss": 0.169,
      "step": 1033
    },
    {
      "epoch": 8.27,
      "grad_norm": 1.2749723196029663,
      "learning_rate": 7.703238352433762e-06,
      "loss": 0.1367,
      "step": 1034
    },
    {
      "epoch": 8.28,
      "grad_norm": 1.1021196842193604,
      "learning_rate": 7.63426475211113e-06,
      "loss": 0.1133,
      "step": 1035
    },
    {
      "epoch": 8.29,
      "grad_norm": 1.2840958833694458,
      "learning_rate": 7.565575800361168e-06,
      "loss": 0.13,
      "step": 1036
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.2728240489959717,
      "learning_rate": 7.497171958693927e-06,
      "loss": 0.1395,
      "step": 1037
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.6706598997116089,
      "learning_rate": 7.429053686703835e-06,
      "loss": 0.1544,
      "step": 1038
    },
    {
      "epoch": 8.31,
      "grad_norm": 1.2799979448318481,
      "learning_rate": 7.361221442066607e-06,
      "loss": 0.123,
      "step": 1039
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.2015994787216187,
      "learning_rate": 7.293675680536227e-06,
      "loss": 0.104,
      "step": 1040
    },
    {
      "epoch": 8.33,
      "grad_norm": 1.1434953212738037,
      "learning_rate": 7.226416855941814e-06,
      "loss": 0.0844,
      "step": 1041
    },
    {
      "epoch": 8.34,
      "grad_norm": 1.7261388301849365,
      "learning_rate": 7.159445420184591e-06,
      "loss": 0.121,
      "step": 1042
    },
    {
      "epoch": 8.34,
      "grad_norm": 1.2435556650161743,
      "learning_rate": 7.092761823234911e-06,
      "loss": 0.1177,
      "step": 1043
    },
    {
      "epoch": 8.35,
      "grad_norm": 1.0044687986373901,
      "learning_rate": 7.0263665131291405e-06,
      "loss": 0.1235,
      "step": 1044
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.0494821071624756,
      "learning_rate": 6.960259935966712e-06,
      "loss": 0.1205,
      "step": 1045
    },
    {
      "epoch": 8.37,
      "grad_norm": 1.4230625629425049,
      "learning_rate": 6.894442535907086e-06,
      "loss": 0.1282,
      "step": 1046
    },
    {
      "epoch": 8.38,
      "grad_norm": 1.3599718809127808,
      "learning_rate": 6.828914755166827e-06,
      "loss": 0.1473,
      "step": 1047
    },
    {
      "epoch": 8.38,
      "grad_norm": 1.7434442043304443,
      "learning_rate": 6.763677034016569e-06,
      "loss": 0.146,
      "step": 1048
    },
    {
      "epoch": 8.39,
      "grad_norm": 1.6534215211868286,
      "learning_rate": 6.698729810778065e-06,
      "loss": 0.1655,
      "step": 1049
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.7295860052108765,
      "learning_rate": 6.63407352182131e-06,
      "loss": 0.1989,
      "step": 1050
    },
    {
      "epoch": 8.41,
      "grad_norm": 1.3957511186599731,
      "learning_rate": 6.5697086015615135e-06,
      "loss": 0.1391,
      "step": 1051
    },
    {
      "epoch": 8.42,
      "grad_norm": 1.2621181011199951,
      "learning_rate": 6.5056354824562295e-06,
      "loss": 0.1538,
      "step": 1052
    },
    {
      "epoch": 8.42,
      "grad_norm": 1.63563072681427,
      "learning_rate": 6.441854595002477e-06,
      "loss": 0.1665,
      "step": 1053
    },
    {
      "epoch": 8.43,
      "grad_norm": 1.29328191280365,
      "learning_rate": 6.37836636773379e-06,
      "loss": 0.0932,
      "step": 1054
    },
    {
      "epoch": 8.44,
      "grad_norm": 1.8491758108139038,
      "learning_rate": 6.315171227217365e-06,
      "loss": 0.1919,
      "step": 1055
    },
    {
      "epoch": 8.45,
      "grad_norm": 1.2036380767822266,
      "learning_rate": 6.2522695980512195e-06,
      "loss": 0.1184,
      "step": 1056
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.6857256889343262,
      "learning_rate": 6.189661902861288e-06,
      "loss": 0.1859,
      "step": 1057
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.368314266204834,
      "learning_rate": 6.1273485622986185e-06,
      "loss": 0.1255,
      "step": 1058
    },
    {
      "epoch": 8.47,
      "grad_norm": 1.2502117156982422,
      "learning_rate": 6.065329995036573e-06,
      "loss": 0.1455,
      "step": 1059
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.5385459661483765,
      "learning_rate": 6.003606617767893e-06,
      "loss": 0.16,
      "step": 1060
    },
    {
      "epoch": 8.49,
      "grad_norm": 1.3959981203079224,
      "learning_rate": 5.942178845202079e-06,
      "loss": 0.1876,
      "step": 1061
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.6458299160003662,
      "learning_rate": 5.881047090062475e-06,
      "loss": 0.1232,
      "step": 1062
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.2063251733779907,
      "learning_rate": 5.820211763083494e-06,
      "loss": 0.1259,
      "step": 1063
    },
    {
      "epoch": 8.51,
      "grad_norm": 1.859677791595459,
      "learning_rate": 5.759673273007954e-06,
      "loss": 0.2151,
      "step": 1064
    },
    {
      "epoch": 8.52,
      "grad_norm": 1.3750971555709839,
      "learning_rate": 5.699432026584267e-06,
      "loss": 0.1273,
      "step": 1065
    },
    {
      "epoch": 8.53,
      "grad_norm": 1.2436949014663696,
      "learning_rate": 5.6394884285636554e-06,
      "loss": 0.1182,
      "step": 1066
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.3397070169448853,
      "learning_rate": 5.579842881697556e-06,
      "loss": 0.1263,
      "step": 1067
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.3894250392913818,
      "learning_rate": 5.520495786734814e-06,
      "loss": 0.135,
      "step": 1068
    },
    {
      "epoch": 8.55,
      "grad_norm": 1.3796437978744507,
      "learning_rate": 5.4614475424190185e-06,
      "loss": 0.1288,
      "step": 1069
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.1343483924865723,
      "learning_rate": 5.402698545485868e-06,
      "loss": 0.1221,
      "step": 1070
    },
    {
      "epoch": 8.57,
      "grad_norm": 2.18361759185791,
      "learning_rate": 5.344249190660428e-06,
      "loss": 0.1618,
      "step": 1071
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.5372682809829712,
      "learning_rate": 5.286099870654515e-06,
      "loss": 0.1603,
      "step": 1072
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.32570219039917,
      "learning_rate": 5.228250976164095e-06,
      "loss": 0.1358,
      "step": 1073
    },
    {
      "epoch": 8.59,
      "grad_norm": 1.2476990222930908,
      "learning_rate": 5.170702895866591e-06,
      "loss": 0.1222,
      "step": 1074
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.53982412815094,
      "learning_rate": 5.1134560164183055e-06,
      "loss": 0.1411,
      "step": 1075
    },
    {
      "epoch": 8.61,
      "grad_norm": 1.3882206678390503,
      "learning_rate": 5.056510722451863e-06,
      "loss": 0.1416,
      "step": 1076
    },
    {
      "epoch": 8.62,
      "grad_norm": 1.276174783706665,
      "learning_rate": 4.999867396573499e-06,
      "loss": 0.1353,
      "step": 1077
    },
    {
      "epoch": 8.62,
      "grad_norm": 1.74802827835083,
      "learning_rate": 4.943526419360661e-06,
      "loss": 0.176,
      "step": 1078
    },
    {
      "epoch": 8.63,
      "grad_norm": 1.46169114112854,
      "learning_rate": 4.8874881693593384e-06,
      "loss": 0.1458,
      "step": 1079
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.357865571975708,
      "learning_rate": 4.831753023081493e-06,
      "loss": 0.1594,
      "step": 1080
    },
    {
      "epoch": 8.65,
      "grad_norm": 1.545548677444458,
      "learning_rate": 4.7763213550026495e-06,
      "loss": 0.1774,
      "step": 1081
    },
    {
      "epoch": 8.66,
      "grad_norm": 0.962204098701477,
      "learning_rate": 4.72119353755931e-06,
      "loss": 0.0941,
      "step": 1082
    },
    {
      "epoch": 8.66,
      "grad_norm": 1.656583547592163,
      "learning_rate": 4.666369941146376e-06,
      "loss": 0.1964,
      "step": 1083
    },
    {
      "epoch": 8.67,
      "grad_norm": 1.491476058959961,
      "learning_rate": 4.611850934114825e-06,
      "loss": 0.1541,
      "step": 1084
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.1037050485610962,
      "learning_rate": 4.557636882769101e-06,
      "loss": 0.1005,
      "step": 1085
    },
    {
      "epoch": 8.69,
      "grad_norm": 1.202187418937683,
      "learning_rate": 4.5037281513647e-06,
      "loss": 0.1096,
      "step": 1086
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.7464957237243652,
      "learning_rate": 4.450125102105757e-06,
      "loss": 0.167,
      "step": 1087
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.638842225074768,
      "learning_rate": 4.396828095142535e-06,
      "loss": 0.1678,
      "step": 1088
    },
    {
      "epoch": 8.71,
      "grad_norm": 1.4148300886154175,
      "learning_rate": 4.343837488569058e-06,
      "loss": 0.1619,
      "step": 1089
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.2821557521820068,
      "learning_rate": 4.291153638420731e-06,
      "loss": 0.1676,
      "step": 1090
    },
    {
      "epoch": 8.73,
      "grad_norm": 1.4162136316299438,
      "learning_rate": 4.238776898671865e-06,
      "loss": 0.1289,
      "step": 1091
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.3910853862762451,
      "learning_rate": 4.18670762123336e-06,
      "loss": 0.1539,
      "step": 1092
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.5243494510650635,
      "learning_rate": 4.134946155950348e-06,
      "loss": 0.1707,
      "step": 1093
    },
    {
      "epoch": 8.75,
      "grad_norm": 1.289936900138855,
      "learning_rate": 4.083492850599791e-06,
      "loss": 0.142,
      "step": 1094
    },
    {
      "epoch": 8.76,
      "grad_norm": 1.214767575263977,
      "learning_rate": 4.032348050888179e-06,
      "loss": 0.1241,
      "step": 1095
    },
    {
      "epoch": 8.77,
      "grad_norm": 1.1893748044967651,
      "learning_rate": 3.981512100449231e-06,
      "loss": 0.1277,
      "step": 1096
    },
    {
      "epoch": 8.78,
      "grad_norm": 1.1715471744537354,
      "learning_rate": 3.9309853408415254e-06,
      "loss": 0.1043,
      "step": 1097
    },
    {
      "epoch": 8.78,
      "grad_norm": 1.7880337238311768,
      "learning_rate": 3.880768111546229e-06,
      "loss": 0.1697,
      "step": 1098
    },
    {
      "epoch": 8.79,
      "grad_norm": 1.214597225189209,
      "learning_rate": 3.830860749964876e-06,
      "loss": 0.1088,
      "step": 1099
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.1316457986831665,
      "learning_rate": 3.781263591416989e-06,
      "loss": 0.1195,
      "step": 1100
    },
    {
      "epoch": 8.81,
      "grad_norm": 1.3906629085540771,
      "learning_rate": 3.731976969137929e-06,
      "loss": 0.1509,
      "step": 1101
    },
    {
      "epoch": 8.82,
      "grad_norm": 1.5546437501907349,
      "learning_rate": 3.6830012142765767e-06,
      "loss": 0.1518,
      "step": 1102
    },
    {
      "epoch": 8.82,
      "grad_norm": 1.5347847938537598,
      "learning_rate": 3.6343366558931892e-06,
      "loss": 0.1405,
      "step": 1103
    },
    {
      "epoch": 8.83,
      "grad_norm": 1.4611774682998657,
      "learning_rate": 3.585983620957112e-06,
      "loss": 0.154,
      "step": 1104
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.566729187965393,
      "learning_rate": 3.53794243434461e-06,
      "loss": 0.2056,
      "step": 1105
    },
    {
      "epoch": 8.85,
      "grad_norm": 1.2389423847198486,
      "learning_rate": 3.4902134188367184e-06,
      "loss": 0.1227,
      "step": 1106
    },
    {
      "epoch": 8.86,
      "grad_norm": 1.2746756076812744,
      "learning_rate": 3.4427968951170288e-06,
      "loss": 0.1268,
      "step": 1107
    },
    {
      "epoch": 8.86,
      "grad_norm": 1.334618330001831,
      "learning_rate": 3.3956931817695325e-06,
      "loss": 0.1711,
      "step": 1108
    },
    {
      "epoch": 8.87,
      "grad_norm": 1.6427756547927856,
      "learning_rate": 3.3489025952765427e-06,
      "loss": 0.1486,
      "step": 1109
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.6540281772613525,
      "learning_rate": 3.3024254500164775e-06,
      "loss": 0.1512,
      "step": 1110
    },
    {
      "epoch": 8.89,
      "grad_norm": 1.3549944162368774,
      "learning_rate": 3.2562620582618165e-06,
      "loss": 0.1173,
      "step": 1111
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.1761066913604736,
      "learning_rate": 3.210412730176987e-06,
      "loss": 0.1122,
      "step": 1112
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.3676292896270752,
      "learning_rate": 3.1648777738162494e-06,
      "loss": 0.1302,
      "step": 1113
    },
    {
      "epoch": 8.91,
      "grad_norm": 1.1880325078964233,
      "learning_rate": 3.1196574951216695e-06,
      "loss": 0.1235,
      "step": 1114
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.4513334035873413,
      "learning_rate": 3.0747521979210436e-06,
      "loss": 0.1483,
      "step": 1115
    },
    {
      "epoch": 8.93,
      "grad_norm": 1.3437066078186035,
      "learning_rate": 3.0301621839258497e-06,
      "loss": 0.1216,
      "step": 1116
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.4393880367279053,
      "learning_rate": 2.985887752729222e-06,
      "loss": 0.1418,
      "step": 1117
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.1163108348846436,
      "learning_rate": 2.9419292018039834e-06,
      "loss": 0.1068,
      "step": 1118
    },
    {
      "epoch": 8.95,
      "grad_norm": 1.977625846862793,
      "learning_rate": 2.8982868265005458e-06,
      "loss": 0.1607,
      "step": 1119
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.470838189125061,
      "learning_rate": 2.8549609200450358e-06,
      "loss": 0.1201,
      "step": 1120
    },
    {
      "epoch": 8.97,
      "grad_norm": 1.1719263792037964,
      "learning_rate": 2.8119517735372745e-06,
      "loss": 0.0995,
      "step": 1121
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.1527272462844849,
      "learning_rate": 2.7692596759487877e-06,
      "loss": 0.1146,
      "step": 1122
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.1613597869873047,
      "learning_rate": 2.726884914120936e-06,
      "loss": 0.1252,
      "step": 1123
    },
    {
      "epoch": 8.99,
      "grad_norm": 1.4964878559112549,
      "learning_rate": 2.6848277727629544e-06,
      "loss": 0.1119,
      "step": 1124
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.6820952892303467,
      "learning_rate": 2.6430885344499946e-06,
      "loss": 0.1614,
      "step": 1125
    },
    {
      "epoch": 9.01,
      "grad_norm": 1.726569652557373,
      "learning_rate": 2.6016674796213168e-06,
      "loss": 0.1679,
      "step": 1126
    },
    {
      "epoch": 9.02,
      "grad_norm": 1.3564796447753906,
      "learning_rate": 2.5605648865783316e-06,
      "loss": 0.1537,
      "step": 1127
    },
    {
      "epoch": 9.02,
      "grad_norm": 1.3117518424987793,
      "learning_rate": 2.519781031482754e-06,
      "loss": 0.1479,
      "step": 1128
    },
    {
      "epoch": 9.03,
      "grad_norm": 1.2787247896194458,
      "learning_rate": 2.47931618835478e-06,
      "loss": 0.1182,
      "step": 1129
    },
    {
      "epoch": 9.04,
      "grad_norm": 1.2000598907470703,
      "learning_rate": 2.439170629071175e-06,
      "loss": 0.123,
      "step": 1130
    },
    {
      "epoch": 9.05,
      "grad_norm": 1.5621933937072754,
      "learning_rate": 2.399344623363503e-06,
      "loss": 0.1559,
      "step": 1131
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.4025838375091553,
      "learning_rate": 2.3598384388163197e-06,
      "loss": 0.1538,
      "step": 1132
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.6875804662704468,
      "learning_rate": 2.3206523408653204e-06,
      "loss": 0.1099,
      "step": 1133
    },
    {
      "epoch": 9.07,
      "grad_norm": 1.3912277221679688,
      "learning_rate": 2.2817865927956095e-06,
      "loss": 0.1306,
      "step": 1134
    },
    {
      "epoch": 9.08,
      "grad_norm": 1.2115354537963867,
      "learning_rate": 2.2432414557399194e-06,
      "loss": 0.1047,
      "step": 1135
    },
    {
      "epoch": 9.09,
      "grad_norm": 1.1715281009674072,
      "learning_rate": 2.2050171886768112e-06,
      "loss": 0.1164,
      "step": 1136
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.1619431972503662,
      "learning_rate": 2.1671140484290142e-06,
      "loss": 0.1269,
      "step": 1137
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.4701294898986816,
      "learning_rate": 2.129532289661651e-06,
      "loss": 0.1587,
      "step": 1138
    },
    {
      "epoch": 9.11,
      "grad_norm": 1.3945281505584717,
      "learning_rate": 2.0922721648805044e-06,
      "loss": 0.1221,
      "step": 1139
    },
    {
      "epoch": 9.12,
      "grad_norm": 1.4144675731658936,
      "learning_rate": 2.0553339244303748e-06,
      "loss": 0.1372,
      "step": 1140
    },
    {
      "epoch": 9.13,
      "grad_norm": 1.0920888185501099,
      "learning_rate": 2.018717816493393e-06,
      "loss": 0.1115,
      "step": 1141
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.1187444925308228,
      "learning_rate": 1.9824240870872703e-06,
      "loss": 0.1086,
      "step": 1142
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.469673752784729,
      "learning_rate": 1.946452980063773e-06,
      "loss": 0.1385,
      "step": 1143
    },
    {
      "epoch": 9.15,
      "grad_norm": 1.3708531856536865,
      "learning_rate": 1.9108047371069914e-06,
      "loss": 0.1078,
      "step": 1144
    },
    {
      "epoch": 9.16,
      "grad_norm": 1.2458689212799072,
      "learning_rate": 1.875479597731733e-06,
      "loss": 0.0889,
      "step": 1145
    },
    {
      "epoch": 9.17,
      "grad_norm": 1.5060348510742188,
      "learning_rate": 1.8404777992819534e-06,
      "loss": 0.1219,
      "step": 1146
    },
    {
      "epoch": 9.18,
      "grad_norm": 1.2473641633987427,
      "learning_rate": 1.805799576929107e-06,
      "loss": 0.1252,
      "step": 1147
    },
    {
      "epoch": 9.18,
      "grad_norm": 1.5773509740829468,
      "learning_rate": 1.7714451636705932e-06,
      "loss": 0.1403,
      "step": 1148
    },
    {
      "epoch": 9.19,
      "grad_norm": 1.322967767715454,
      "learning_rate": 1.7374147903282178e-06,
      "loss": 0.1174,
      "step": 1149
    },
    {
      "epoch": 9.2,
      "grad_norm": 1.6340830326080322,
      "learning_rate": 1.70370868554659e-06,
      "loss": 0.1586,
      "step": 1150
    },
    {
      "epoch": 9.21,
      "grad_norm": 1.1476832628250122,
      "learning_rate": 1.6703270757916001e-06,
      "loss": 0.0917,
      "step": 1151
    },
    {
      "epoch": 9.22,
      "grad_norm": 1.3080719709396362,
      "learning_rate": 1.6372701853489436e-06,
      "loss": 0.1487,
      "step": 1152
    },
    {
      "epoch": 9.22,
      "grad_norm": 1.4102859497070312,
      "learning_rate": 1.604538236322556e-06,
      "loss": 0.1089,
      "step": 1153
    },
    {
      "epoch": 9.23,
      "grad_norm": 1.5242670774459839,
      "learning_rate": 1.5721314486331352e-06,
      "loss": 0.1187,
      "step": 1154
    },
    {
      "epoch": 9.24,
      "grad_norm": 1.3129041194915771,
      "learning_rate": 1.5400500400166939e-06,
      "loss": 0.1176,
      "step": 1155
    },
    {
      "epoch": 9.25,
      "grad_norm": 1.1765007972717285,
      "learning_rate": 1.5082942260230658e-06,
      "loss": 0.1186,
      "step": 1156
    },
    {
      "epoch": 9.26,
      "grad_norm": 1.059391736984253,
      "learning_rate": 1.4768642200144678e-06,
      "loss": 0.1079,
      "step": 1157
    },
    {
      "epoch": 9.26,
      "grad_norm": 1.6927438974380493,
      "learning_rate": 1.4457602331640506e-06,
      "loss": 0.1428,
      "step": 1158
    },
    {
      "epoch": 9.27,
      "grad_norm": 1.3036251068115234,
      "learning_rate": 1.4149824744545238e-06,
      "loss": 0.1316,
      "step": 1159
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.4398090839385986,
      "learning_rate": 1.3845311506766988e-06,
      "loss": 0.1152,
      "step": 1160
    },
    {
      "epoch": 9.29,
      "grad_norm": 1.4908992052078247,
      "learning_rate": 1.3544064664281265e-06,
      "loss": 0.1548,
      "step": 1161
    },
    {
      "epoch": 9.3,
      "grad_norm": 1.2697181701660156,
      "learning_rate": 1.324608624111734e-06,
      "loss": 0.1093,
      "step": 1162
    },
    {
      "epoch": 9.3,
      "grad_norm": 1.0459253787994385,
      "learning_rate": 1.2951378239344336e-06,
      "loss": 0.1094,
      "step": 1163
    },
    {
      "epoch": 9.31,
      "grad_norm": 1.3033581972122192,
      "learning_rate": 1.2659942639057953e-06,
      "loss": 0.1333,
      "step": 1164
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.0681346654891968,
      "learning_rate": 1.2371781398367311e-06,
      "loss": 0.0812,
      "step": 1165
    },
    {
      "epoch": 9.33,
      "grad_norm": 1.3850475549697876,
      "learning_rate": 1.2086896453381402e-06,
      "loss": 0.1155,
      "step": 1166
    },
    {
      "epoch": 9.34,
      "grad_norm": 1.4358758926391602,
      "learning_rate": 1.18052897181965e-06,
      "loss": 0.1191,
      "step": 1167
    },
    {
      "epoch": 9.34,
      "grad_norm": 1.0497169494628906,
      "learning_rate": 1.1526963084882992e-06,
      "loss": 0.0976,
      "step": 1168
    },
    {
      "epoch": 9.35,
      "grad_norm": 1.4460210800170898,
      "learning_rate": 1.1251918423472895e-06,
      "loss": 0.1107,
      "step": 1169
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.5334272384643555,
      "learning_rate": 1.0980157581947038e-06,
      "loss": 0.1335,
      "step": 1170
    },
    {
      "epoch": 9.37,
      "grad_norm": 1.14414381980896,
      "learning_rate": 1.0711682386222943e-06,
      "loss": 0.0973,
      "step": 1171
    },
    {
      "epoch": 9.38,
      "grad_norm": 1.1719380617141724,
      "learning_rate": 1.0446494640142412e-06,
      "loss": 0.107,
      "step": 1172
    },
    {
      "epoch": 9.38,
      "grad_norm": 1.4209460020065308,
      "learning_rate": 1.0184596125459135e-06,
      "loss": 0.1553,
      "step": 1173
    },
    {
      "epoch": 9.39,
      "grad_norm": 1.4018141031265259,
      "learning_rate": 9.925988601827418e-07,
      "loss": 0.1259,
      "step": 1174
    },
    {
      "epoch": 9.4,
      "grad_norm": 1.1261390447616577,
      "learning_rate": 9.670673806789544e-07,
      "loss": 0.0854,
      "step": 1175
    },
    {
      "epoch": 9.41,
      "grad_norm": 1.3205451965332031,
      "learning_rate": 9.418653455764592e-07,
      "loss": 0.1261,
      "step": 1176
    },
    {
      "epoch": 9.42,
      "grad_norm": 1.4616074562072754,
      "learning_rate": 9.169929242036967e-07,
      "loss": 0.1409,
      "step": 1177
    },
    {
      "epoch": 9.42,
      "grad_norm": 1.5699981451034546,
      "learning_rate": 8.924502836744563e-07,
      "loss": 0.2247,
      "step": 1178
    },
    {
      "epoch": 9.43,
      "grad_norm": 1.453263759613037,
      "learning_rate": 8.682375888868166e-07,
      "loss": 0.1204,
      "step": 1179
    },
    {
      "epoch": 9.44,
      "grad_norm": 1.7035400867462158,
      "learning_rate": 8.443550025219793e-07,
      "loss": 0.1204,
      "step": 1180
    },
    {
      "epoch": 9.45,
      "grad_norm": 1.7035400867462158,
      "learning_rate": 8.443550025219793e-07,
      "loss": 0.0841,
      "step": 1181
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.2525593042373657,
      "learning_rate": 8.208026850431982e-07,
      "loss": 0.0945,
      "step": 1182
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.5361721515655518,
      "learning_rate": 7.975807946947245e-07,
      "loss": 0.1274,
      "step": 1183
    },
    {
      "epoch": 9.47,
      "grad_norm": 1.1375094652175903,
      "learning_rate": 7.746894875007016e-07,
      "loss": 0.0948,
      "step": 1184
    },
    {
      "epoch": 9.48,
      "grad_norm": 1.7220875024795532,
      "learning_rate": 7.521289172641554e-07,
      "loss": 0.1461,
      "step": 1185
    },
    {
      "epoch": 9.49,
      "grad_norm": 1.3528720140457153,
      "learning_rate": 7.29899235565934e-07,
      "loss": 0.1124,
      "step": 1186
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.2975066900253296,
      "learning_rate": 7.080005917636967e-07,
      "loss": 0.1227,
      "step": 1187
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.0643059015274048,
      "learning_rate": 6.864331329909102e-07,
      "loss": 0.1069,
      "step": 1188
    },
    {
      "epoch": 9.51,
      "grad_norm": 1.2855814695358276,
      "learning_rate": 6.651970041558763e-07,
      "loss": 0.1185,
      "step": 1189
    },
    {
      "epoch": 9.52,
      "grad_norm": 1.4029490947723389,
      "learning_rate": 6.442923479407336e-07,
      "loss": 0.16,
      "step": 1190
    },
    {
      "epoch": 9.53,
      "grad_norm": 1.4882534742355347,
      "learning_rate": 6.237193048005019e-07,
      "loss": 0.1547,
      "step": 1191
    },
    {
      "epoch": 9.54,
      "grad_norm": 1.2194222211837769,
      "learning_rate": 6.034780129621664e-07,
      "loss": 0.124,
      "step": 1192
    },
    {
      "epoch": 9.54,
      "grad_norm": 1.7414799928665161,
      "learning_rate": 5.835686084237069e-07,
      "loss": 0.1356,
      "step": 1193
    },
    {
      "epoch": 9.55,
      "grad_norm": 1.3990439176559448,
      "learning_rate": 5.639912249532198e-07,
      "loss": 0.1259,
      "step": 1194
    },
    {
      "epoch": 9.56,
      "grad_norm": 1.0070632696151733,
      "learning_rate": 5.447459940880084e-07,
      "loss": 0.0806,
      "step": 1195
    },
    {
      "epoch": 9.57,
      "grad_norm": 1.747745394706726,
      "learning_rate": 5.258330451336724e-07,
      "loss": 0.1561,
      "step": 1196
    },
    {
      "epoch": 9.58,
      "grad_norm": 1.2481920719146729,
      "learning_rate": 5.072525051632915e-07,
      "loss": 0.094,
      "step": 1197
    },
    {
      "epoch": 9.58,
      "grad_norm": 0.9113856554031372,
      "learning_rate": 4.890044990165321e-07,
      "loss": 0.0764,
      "step": 1198
    },
    {
      "epoch": 9.59,
      "grad_norm": 1.3412500619888306,
      "learning_rate": 4.710891492988034e-07,
      "loss": 0.1174,
      "step": 1199
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.2495285272598267,
      "learning_rate": 4.535065763804802e-07,
      "loss": 0.1329,
      "step": 1200
    },
    {
      "epoch": 9.61,
      "grad_norm": 1.074975848197937,
      "learning_rate": 4.362568983960369e-07,
      "loss": 0.1073,
      "step": 1201
    },
    {
      "epoch": 9.62,
      "grad_norm": 1.470718502998352,
      "learning_rate": 4.1934023124329257e-07,
      "loss": 0.1264,
      "step": 1202
    },
    {
      "epoch": 9.62,
      "grad_norm": 1.310308814048767,
      "learning_rate": 4.0275668858261726e-07,
      "loss": 0.1299,
      "step": 1203
    },
    {
      "epoch": 9.63,
      "grad_norm": 1.0562347173690796,
      "learning_rate": 3.8650638183617694e-07,
      "loss": 0.148,
      "step": 1204
    },
    {
      "epoch": 9.64,
      "grad_norm": 1.5023252964019775,
      "learning_rate": 3.7058942018716183e-07,
      "loss": 0.1441,
      "step": 1205
    },
    {
      "epoch": 9.65,
      "grad_norm": 1.4258500337600708,
      "learning_rate": 3.550059105790926e-07,
      "loss": 0.1373,
      "step": 1206
    },
    {
      "epoch": 9.66,
      "grad_norm": 1.1633763313293457,
      "learning_rate": 3.3975595771506e-07,
      "loss": 0.1093,
      "step": 1207
    },
    {
      "epoch": 9.66,
      "grad_norm": 1.0974057912826538,
      "learning_rate": 3.248396640570528e-07,
      "loss": 0.1113,
      "step": 1208
    },
    {
      "epoch": 9.67,
      "grad_norm": 1.1854184865951538,
      "learning_rate": 3.102571298252588e-07,
      "loss": 0.1268,
      "step": 1209
    },
    {
      "epoch": 9.68,
      "grad_norm": 1.241304874420166,
      "learning_rate": 2.9600845299737056e-07,
      "loss": 0.1143,
      "step": 1210
    },
    {
      "epoch": 9.69,
      "grad_norm": 1.1760616302490234,
      "learning_rate": 2.820937293079695e-07,
      "loss": 0.122,
      "step": 1211
    },
    {
      "epoch": 9.7,
      "grad_norm": 1.440239667892456,
      "learning_rate": 2.6851305224784853e-07,
      "loss": 0.1229,
      "step": 1212
    },
    {
      "epoch": 9.7,
      "grad_norm": 1.173656940460205,
      "learning_rate": 2.552665130633958e-07,
      "loss": 0.1366,
      "step": 1213
    },
    {
      "epoch": 9.71,
      "grad_norm": 1.2472383975982666,
      "learning_rate": 2.423542007559787e-07,
      "loss": 0.1343,
      "step": 1214
    },
    {
      "epoch": 9.72,
      "grad_norm": 1.3806341886520386,
      "learning_rate": 2.2977620208135542e-07,
      "loss": 0.1227,
      "step": 1215
    },
    {
      "epoch": 9.73,
      "grad_norm": 1.3556110858917236,
      "learning_rate": 2.1753260154906973e-07,
      "loss": 0.1396,
      "step": 1216
    },
    {
      "epoch": 9.74,
      "grad_norm": 1.153934359550476,
      "learning_rate": 2.0562348142191824e-07,
      "loss": 0.1101,
      "step": 1217
    },
    {
      "epoch": 9.74,
      "grad_norm": 1.6550453901290894,
      "learning_rate": 1.9404892171536183e-07,
      "loss": 0.1147,
      "step": 1218
    },
    {
      "epoch": 9.75,
      "grad_norm": 1.271003007888794,
      "learning_rate": 1.8280900019701508e-07,
      "loss": 0.1281,
      "step": 1219
    },
    {
      "epoch": 9.76,
      "grad_norm": 1.3726433515548706,
      "learning_rate": 1.7190379238609666e-07,
      "loss": 0.1304,
      "step": 1220
    },
    {
      "epoch": 9.77,
      "grad_norm": 1.4199883937835693,
      "learning_rate": 1.6133337155294637e-07,
      "loss": 0.1246,
      "step": 1221
    },
    {
      "epoch": 9.78,
      "grad_norm": 1.326910376548767,
      "learning_rate": 1.5109780871853663e-07,
      "loss": 0.1435,
      "step": 1222
    },
    {
      "epoch": 9.78,
      "grad_norm": 1.2586113214492798,
      "learning_rate": 1.4119717265396182e-07,
      "loss": 0.1229,
      "step": 1223
    },
    {
      "epoch": 9.79,
      "grad_norm": 1.5069880485534668,
      "learning_rate": 1.3163152988000528e-07,
      "loss": 0.1644,
      "step": 1224
    },
    {
      "epoch": 9.8,
      "grad_norm": 1.5849791765213013,
      "learning_rate": 1.2240094466668406e-07,
      "loss": 0.1165,
      "step": 1225
    },
    {
      "epoch": 9.81,
      "grad_norm": 1.4544552564620972,
      "learning_rate": 1.1350547903282716e-07,
      "loss": 0.1367,
      "step": 1226
    },
    {
      "epoch": 9.82,
      "grad_norm": 1.35446035861969,
      "learning_rate": 1.0494519274562575e-07,
      "loss": 0.1021,
      "step": 1227
    },
    {
      "epoch": 9.82,
      "grad_norm": 1.0719558000564575,
      "learning_rate": 9.672014332028356e-08,
      "loss": 0.1131,
      "step": 1228
    },
    {
      "epoch": 9.83,
      "grad_norm": 1.4475046396255493,
      "learning_rate": 8.883038601957827e-08,
      "loss": 0.1051,
      "step": 1229
    },
    {
      "epoch": 9.84,
      "grad_norm": 1.3997293710708618,
      "learning_rate": 8.127597385352293e-08,
      "loss": 0.1713,
      "step": 1230
    },
    {
      "epoch": 9.85,
      "grad_norm": 1.1048460006713867,
      "learning_rate": 7.405695757899955e-08,
      "loss": 0.1172,
      "step": 1231
    },
    {
      "epoch": 9.86,
      "grad_norm": 1.3421950340270996,
      "learning_rate": 6.717338569942611e-08,
      "loss": 0.1055,
      "step": 1232
    },
    {
      "epoch": 9.86,
      "grad_norm": 1.2839570045471191,
      "learning_rate": 6.062530446440673e-08,
      "loss": 0.1094,
      "step": 1233
    },
    {
      "epoch": 9.87,
      "grad_norm": 1.3877372741699219,
      "learning_rate": 5.4412757869459763e-08,
      "loss": 0.1311,
      "step": 1234
    },
    {
      "epoch": 9.88,
      "grad_norm": 1.3316335678100586,
      "learning_rate": 4.853578765567357e-08,
      "loss": 0.1563,
      "step": 1235
    },
    {
      "epoch": 9.89,
      "grad_norm": 1.215183973312378,
      "learning_rate": 4.299443330947894e-08,
      "loss": 0.1053,
      "step": 1236
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.3396998643875122,
      "learning_rate": 3.778873206234379e-08,
      "loss": 0.1248,
      "step": 1237
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.6877708435058594,
      "learning_rate": 3.2918718890534436e-08,
      "loss": 0.1546,
      "step": 1238
    },
    {
      "epoch": 9.91,
      "grad_norm": 1.1745569705963135,
      "learning_rate": 2.8384426514893592e-08,
      "loss": 0.1077,
      "step": 1239
    },
    {
      "epoch": 9.92,
      "grad_norm": 1.0637966394424438,
      "learning_rate": 2.4185885400596075e-08,
      "loss": 0.0901,
      "step": 1240
    },
    {
      "epoch": 9.93,
      "grad_norm": 1.4184436798095703,
      "learning_rate": 2.032312375697121e-08,
      "loss": 0.1458,
      "step": 1241
    },
    {
      "epoch": 9.94,
      "grad_norm": 1.6129852533340454,
      "learning_rate": 1.6796167537297404e-08,
      "loss": 0.1744,
      "step": 1242
    },
    {
      "epoch": 9.94,
      "grad_norm": 1.362457036972046,
      "learning_rate": 1.3605040438618988e-08,
      "loss": 0.1352,
      "step": 1243
    },
    {
      "epoch": 9.95,
      "grad_norm": 1.3643310070037842,
      "learning_rate": 1.0749763901607423e-08,
      "loss": 0.1308,
      "step": 1244
    },
    {
      "epoch": 9.96,
      "grad_norm": 1.2247364521026611,
      "learning_rate": 8.230357110416975e-09,
      "loss": 0.1149,
      "step": 1245
    },
    {
      "epoch": 9.97,
      "grad_norm": 1.532755732536316,
      "learning_rate": 6.04683699252373e-09,
      "loss": 0.1341,
      "step": 1246
    },
    {
      "epoch": 9.98,
      "grad_norm": 1.2651057243347168,
      "learning_rate": 4.1992182186589845e-09,
      "loss": 0.115,
      "step": 1247
    },
    {
      "epoch": 9.98,
      "grad_norm": 1.1651513576507568,
      "learning_rate": 2.6875132026760175e-09,
      "loss": 0.1352,
      "step": 1248
    },
    {
      "epoch": 9.99,
      "grad_norm": 1.9331978559494019,
      "learning_rate": 1.511732101472374e-09,
      "loss": 0.1705,
      "step": 1249
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.0665934085845947,
      "learning_rate": 6.718828149343548e-10,
      "loss": 0.1047,
      "step": 1250
    },
    {
      "epoch": 10.0,
      "step": 1250,
      "total_flos": 2.977581233078272e+16,
      "train_loss": 0.6488813472509384,
      "train_runtime": 2997.8153,
      "train_samples_per_second": 3.336,
      "train_steps_per_second": 0.417
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 1250,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 100,
  "total_flos": 2.977581233078272e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
