### Evaluation Result

| Model Type | Model Name | Sample 20 Acc | Sample 50 Acc | Sample 100 Acc |
|------------|------------|-------| -------- | -------- |
| llama3 based | meta-llama/Meta-Llama-3-8B-Instruct | 80 | 82 | - |
| llama3 based | UnicomLLM/Unichat-llama3-Chinese-8B | 55 | - | - |
| llama2 based | meta-llama/Llama-2-7b-chat-hf | 50 | - | - |
| llama2 based | meta-llama/Llama-2-13b-chat-hf | - | - | - |
| llama2 based | taide/TAIDE-LX-7B-Chat | - | 多題拒絕回答 | - |
| llama2 based | yentinglin/Taiwan-LLM-7B-v2.1-chat | 25 | - | - |
| llama2 based | yentinglin/Taiwan-LLM-13B-v2.0-chat | - | - | - |
| Mistral based | mistralai/Mistral-7B-Instruct-v0.2 | 75 | 72 | - |
| Mistral based | MediaTek-Research/Breeze-7B-Instruct-v1_0 | 80 | 90 | 90 |
| Gemma based | google/gemma-1.1-7b-it | 80 | 88 | - |
| Phi based | microsoft/phi-3-mini-4k-instruct | - | 54 | - |